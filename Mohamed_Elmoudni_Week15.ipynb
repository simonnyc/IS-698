{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name: Mohamed Elmoudni\n",
    "#### Class: Machine Learning and Big Data DATA 622\n",
    "#### Week 15 - Tuning your model\n",
    "#### Assignment: W15 Project\n",
    "\n",
    "\n",
    "###### W15 Project\n",
    "\n",
    "Incorporate all lessons to improve the performance of the classification using the raw dataset. Submit source code and error measures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning steps:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "To improve the classification, I will be looking to tune two major areas:\n",
    "    \n",
    "    1-    The Data \n",
    "    2-    The Algorithm.  \n",
    "\n",
    "To improve data I will be looking at the following areas: \n",
    "    \n",
    "    Rescale the data. \n",
    "    Transform the data.\n",
    "    \n",
    "To improve the algorithm, I will be looking at tuning the below areas by Grid-Searching the hyper parameters when applicable:\n",
    "    \n",
    "1- Diagnostics: Is the model overfitting or under fitting?\n",
    "    \n",
    "2- Learning Rate: I will experiment with very small learning rates and large rates. I will try adding momentum term; then change the learning rate.\n",
    "    \n",
    "3- Activation Functions: I will be experimenting using the different activation function sigmoid,tanh, relu, then a softmax, linear or sigmoid on the output layer\n",
    "    \n",
    "4- Network Topology: I will be changing the network topology by using different number of layers and neurons\n",
    "    \n",
    "5- Batches and Epochs: The batch size defines the gradient and how often to update weights. An epoch is the entire training data exposed to the network, batch-by-batch. I will be experimenting running small batch sizes with large epoch size.\n",
    "    \n",
    "6- Regularization: regularization is a great approach to curb overfitting the training data. I will be using the dropout regularization technique. Dropout randomly skips neurons during training, forcing others in the layer to pick up the slack. I will be experimenting with dropout in the input, hidden, and output layers.\n",
    "    \n",
    "7- Optimization and Loss: There are many optimization methods that offer more parameters, more complexity and faster convergence. However, for our classification problem, we will be mainly experimenting with the followings: adam and RMSprop\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### For the above tuning steps, I will be using three models as follow: "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "First, I will be building three models as follow:  \n",
    "\n",
    "First ModelL model 1 \n",
    "1. Construct a neural network: baseline model model_1\n",
    "The major components of our initial CNN model can be summarized as follows:\n",
    "1- The first hidden layer is a convolutional layer called a Convolution2D. The layer has 15 feature   maps, which with the size of 5x5 and a rectifier activation function.\n",
    "2- Next we define a pooling layer that takes the maximum value called MaxPooling2D. It is configured with a pool size of 2 x2.\n",
    "3- The next layer is a regularization layer using dropout called Dropout. It is configured to randomly exclude 20% of neurons in the layer in order to reduce overfitting.\n",
    "4- Next is a layer that converts the 2D matrix data to a vector called Flatten. It allows the output to be processed by standard fully connected layers.\n",
    "5- Next a fully connected layer with 10 neurons and rectifier activation function is used.\n",
    "5- Finally, the output layer has 10 neurons for the 10 classes and a softmax activation function to output probability-like predictions for each class.\n",
    "\n",
    "\n",
    "Second Model: model_2\n",
    "The major components of our second CNN modle can be summarized as follows: 1- Convolutional layer with 15 feature maps of size 5x5.\n",
    "2- Pooling layer taking the max over 2x2 patches.\n",
    "3- Convolutional layer with 10 feature maps of size 3x3.\n",
    "4- Pooling layer taking the max over 2x2 patches.\n",
    "5- Dropout layer with a probability of 20%.\n",
    "6- Flatten layer.\n",
    "7- Fully connected layer with 10 neurons and rectifier activation.\n",
    "8- Fully connected layer with 10 neurons and rectifier activation.\n",
    "9- Fully connected layer with 100 neurons and rectifier activation.\n",
    "10- Output layer.\n",
    "\n",
    "\n",
    "Third Model: model_3\n",
    "The major components of our second CNN modle can be summarized as follows: 1- Convolutional layer with 30feature maps of size 5x5.\n",
    "2- Pooling layer taking the max over 2x2 patches.\n",
    "3- Convolutional layer with 50 feature maps of size 5x5.\n",
    "4- Pooling layer taking the max over 2x2 patches.\n",
    "5- Convolutional layer with 50 feature maps of size 5x5.\n",
    "6- Pooling layer taking the max over 2x2 patches.\n",
    "5- Dropout layer with a probability of 20%.\n",
    "7- Flatten layer.\n",
    "8- Fully connected layer with 10 neurons and rectifier activation.\n",
    "9- Fully connected layer with 10 neurons and rectifier activation.\n",
    "10- Output layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import time\n",
    "from scipy import misc\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from PIL import Image\n",
    "from StringIO import StringIO\n",
    "import requests\n",
    "import numpy as np\n",
    "import requests\n",
    "##\n",
    "import numpy\n",
    "#K.set_image_dim_ordering('th')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (10,10) # Make the figures a bit bigger\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "##\n",
    "# image proccesssing \n",
    "import PIL\n",
    "from PIL import Image\n",
    "from StringIO import StringIO\n",
    "import requests\n",
    "from resizeimage import resizeimage\n",
    "\n",
    "import keras.callbacks as cb\n",
    "import keras.utils.np_utils as np_utils\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import MaxPooling2D, ZeroPadding2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 1)\n",
      "(2000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#####################################################################################\n",
    " # Load the CSV meta data\n",
    "######################################################################################\n",
    "\n",
    "\n",
    "def load_face_data(csvdata, total, basewidth): \n",
    "    # initial our array 28x28 image size \n",
    "    X_data = np.zeros([total, basewidth, basewidth])\n",
    "    Y_data = np.zeros([total, 1], dtype=np.int8)\n",
    "    df = []\n",
    "    csvdf= (csvdata[['image', 'emotion']]).head(total)\n",
    "    #print csvdf['image'][0]\n",
    "    for i in range(0,total-1):\n",
    "        img9 = 'https://raw.githubusercontent.com/muxspace/facial_expressions/master/images/'+csvdf['image'][i]\n",
    "        #print(img9)\n",
    "        r = requests.get(img9)\n",
    "        im = Image.open(StringIO(r.content))\n",
    "        wpercent = (basewidth / float(im.size[0]))\n",
    "        hsize = int((float(im.size[1]) * float(wpercent)))\n",
    "        im = im.resize((basewidth, hsize), PIL.Image.ANTIALIAS)\n",
    "        #im = resizeimage.resize_crop(im, [basewidth, basewidth])\n",
    "        image = img_to_array(im)\n",
    "        #df = np.asarray([image,csvdf['emotion']])\n",
    "        df = ([image,csvdf['emotion']])\n",
    "        X_data[i] = np.asarray(image)\n",
    "        if  (df[1][i]).strip().lower()== 'happiness': \n",
    "            Y_data[i] =1\n",
    "        if  (df[1][i]).strip().lower()== 'anger': \n",
    "            Y_data[i] =2\n",
    "        if  (df[1][i]).strip().lower()== 'disgust': \n",
    "            Y_data[i] =3\n",
    "        if  (df[1][i]).strip().lower()== 'fear': \n",
    "            Y_data[i] =4\n",
    "        if  (df[1][i]).strip().lower()== 'neutral': \n",
    "            Y_data[i] =5\n",
    "        if  (df[1][i]).strip().lower()== 'sadness': \n",
    "            Y_data[i] =6\n",
    "        if  (df[1][i]).strip().lower()== 'surprise': \n",
    "            Y_data[i] =7\n",
    "        if  (df[1][i]).strip().lower()== 'contempt': \n",
    "            Y_data[i] =8\n",
    "    return X_data, Y_data  \n",
    "\n",
    "##########\n",
    "\n",
    "csvdata = pd.read_csv('https://raw.githubusercontent.com/muxspace/facial_expressions/master/data/legend.csv', \n",
    "                  skiprows=range(1, 5))\n",
    "\n",
    "total = len(csvdata)\n",
    "basewidth = 28\n",
    "total =2000\n",
    "X_data, Y_data = load_face_data(csvdata, total, basewidth)\n",
    "print (Y_data.shape)\n",
    "print (X_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainNdx = int(100 * .8)\n",
    "X_train, X_test = np.split(X_data, [trainNdx])\n",
    "y_train, y_test = np.split(Y_data, [trainNdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD2CAYAAAB1JFQuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsvXmMpFua3vVERGZkxppbZdWtvtfdt3uAGWQxlhHbtKXB\nyAaExCZmsA3WwFhgMFi2hQAB/2BbCNksEouRhWSBx4jFLGMW/2FGZsBjtW3Ads94FgtQd0/3TN97\nu+tWVS6RsWRmLPwR+Tv5fG+eiMxbGXW7xz6vFMrMyIjvO+c973nO8y7nfFKRIkWKFClSpEiRIkWK\nFClSpEiRIkWKFClSpEiRIkWKFClSpEiRIkWKFClS5A1lJumnJf2spD8hqbuh6/6opD+0oWu5/IOS\nvizpZyT9gqR/7i3cw+X3SfqXb37//ZJ+w1u+3z8u6a9K+snw/vuSxlqO1U9rqYOtt3D/H5X0sd3n\npyV93wau+49I+pvt709Dl0WKfFfKwH7/Md0CzGPlR7V50N2W9IGkz9jff9OG7xHl92pzOnmI/K+S\nvph5/31JP/cp3P+flvQfv4Xr/pikH3oL1y3ylqX+nW7AX+PyFyR9z83vf4ekP68lo/pzugW3H9WS\nEf8pSf+fpH/Hvv/bJP2/kv4vVYHjfUn/u6S/Iul/k/Srbt7/MUl/+Oa+X5X06yX9MS2Z3h/NtK+n\nJbt7ffP39U0bJOkfkvR/3rT3T0t6evP+77u55p+V9HVJ/5ikf19LZv+ndMsWv37Tl5+9aT96cPkx\n3QLH12+u/ZdvvvO9N+8f39z/5yX9kZvPHWau9U/cfO/nJP3Bm/f+TUm/TtJ/LunfzXwnyvs3/frL\nN68fsP/9azfX/xlJf+Dmve/Rss9/6eZ736u81DLv/XpJPyXpf9JyrP6gpB+R9H/f3OcL1qY41l/U\ncnz+PS3H5wuq6vI33Lz/s5L+M0nNm/e/rryOixT5FS0w3YakH5f0L9783bt5T5J+o6T/4eb3H9Vy\n0vUk7Wg5Md6V9FzSNyQdaclAv6RbxvQntZyg0hKY/8eb339M0n998/s/LOlc0q/WctL/JUm/JtPe\nPyLp2zff+yd1CxD79pl/VktglZaT9s/e9OX7JY0k/f03//sTWrq9kvSLkv6Nm99/5KbNUpXp/lEt\nQZvP/86b3/+Fm3ZJ0n+iJeDp5j5z3QXdz+hWVw0tQwm04/+Q9Ldm+v3+Tdtx+f+QpJaWYyBJf6Ok\nv3jz+z+g5UK5e/M3uvlJSX/Dze9/p+6GMKTl+L5QNYyxqyXonkh6piUofqClbiXpd0v6D25+XzXW\nrjv/e1fSL1m7/pik33Pz+yodF/kU5W3EsP56l5aWk+tdLQH0P715f1/Sf6HlZFioqvuf1C1Y/1Ut\nAeFY0p+R9Orm/f9WSyCQpL9L0j968/t/qVsWt9AtuP28pG9pGafVzc/3tWRMLr9d0n+k5ULwr0j6\ne7Wc3L9K0n8n6R0tQeFrdo8/pWXs+ue19JZ+4uZ/Pyfpc3bt/+bm5x/XLYiskz9x8/PLugWUX2d9\n/QktgSrK364luKKr/0rSD0r6n2/+zjFNabnY/Vr7e09LkP81WvYPff9GLdny5ObvUy1j9T8g6b+3\n7zd1VxZa9v93Z/73F7Vc8CTpK7rV489L+ntufl811tLdftW0ZK+/eHM9aQm6v1PLMZbyOi7yKUoJ\nL2xexlpO5M9pOUlhXP+WluD6t2jpGrbsO5f2+0xLQF6E6+YmWE6ubn7Ow3XnWr3I/ryk/1BLwMVF\n/UNaMuvvl/TPh/b6Pa4feI/Fit9daC86QFb11a/nn6k98H5R/iVJH2nZ579Nt6w3Xl9azp1TLcea\n169ecd1V7Y/jc2m/P6T/uX7l7MbfW6XjIp+SFNB9ezLWkt3821oafl/Shzf/+233fHehZRz079bS\nld7WMguP/HlJv+Xm99+qpbv/JtLR0s1Ffq2W7FyhvT9qn7kPAP3/v9l+/nn7/33XcPlzkn7Tze9/\nn6SDzGf+opa6IrzwW7SMl35S6WvpHUjSP6XbcNCf1nLMWHgOtAzd/KKkH755r6YlWEf5JH3Nyaqx\nHty012WhZQ7gfd3G0H9Eb6aLIm9JCuhuXpxV/IyWbt5v0tIt/ANaunUN+9xCecbyLS1jfH9By3ju\nL9j/fpeWIPBXtJyIv8f+t47h5VjQvyrp/9EyJPJ7dQuwv09L1/kvaVnytKq96+5xcNPG36Uli8x9\nPyf+md+vJdj+nJYA9y1VK0SkJTv917UMMfzMTZv/pO6X2I4/rGW1wc9o6aZf3Lz/E5L+l5vr/rRu\nY9K/VdI/c/P5n9cyjp67x29WtWTsB7ReD/6/VWP9x7Ucu7+s26SbtGSyv03LsftZSVPdhrjiuD3U\nAyhSpMivAPlF5asMPqk0dcs4f0DLRatIkV+xUmI6Rd6WbIpFfVbLhF5dy1jyb9/QdYsUKVKkSJEi\nRYoUKVKkSJEiRYoUKVKkSJEiRYoUKVKkSJEiRYoUKVKkSJEiRYoUKVKkSJEiRYoUKVKkSJEiRYoU\nKVKkSJEiRYoUKVKkSJEiRYoUKVKkSJEiRYoUKVKkSJEiRYoUKVKkSJEiRYoUKVKkSJEiRYoUKVKk\nSJEiRYoUKVKkSJEiRYoUKVKkSJEiRYoUKVKkSJEiRYoUKVKkSJEiRYoUKVLkrwlptVoLSeW15vXF\nL35x8ab6/cEf/MHvePu/m1+7u7tvrNudnZ3vePu/21/dbveN9Nvv97/jbf9uf93YX1Zq9+h38f3f\n//2aTqfpdX19revra9XrdTUaDW1tbaXf/bW9va1ms6nt7e304vONRkOLxUKLxULz+Vzz+Vyz2Uyz\n2UzT6VTz+Vy1Wq3ySg1a3PalVqupXq9re3tbW1tbajab2tnZ0fb2dvoe15/P57q8vNTl5aUmk4nG\n47HG47FqtZq2trZSe5vNpjqdjo6OjnR0dKT33ntPn/vc5/Tee++p1Wqp1Wqp2Wymfvb7/YfocaV+\nr6+v0x8nJyf65V/+ZX3zm9/Ul7/8ZX35y1/WL/3SL6V7vfvuu/qe7/keffazn019XSwWaUzQR+7F\nmMQXfebFODUaDdXr9aqxhLFgPObzeWUsebnNvHr1St/+9rf14sWL9Do7O9NwONRwOKx85/LyUldX\nV/rKV77yKN1+4QtfuPNmrVZLtlev17W7u6vd3d00tq1W645+tre3NZ1Ok92MRiMNh0PNZrP0nU6n\no263q263q729Pe3t7andbldsn3FA18yFer1+p/+Xl5caDoc6Pz/X+fm5JpOJJpOJrq6u0hyYzWa6\nvr7WdDpN41Kv17W1taWtrS1dX1+na52fn2swGGg8Hqdx+YVf+IU31e/ii1/8Ypqzs9ksjT86dnFb\n8M/TTvTQaDSy39na2tLOzo5arZYODg50cHCgZrOZbAvcQB/X19fa3d3V4eGhDg8PK7o6OztLdsd4\ngku1Wi21D10yB7Cb2Wym+Xyuq6ur9GLsFotFmoPf/OY3V+p26z7tbm1tpRvxk0H3hkyn0wr4xgHx\nwfDJzPdrtVoCBv98Dnj9fwwIRoyBe3un02nqi7cf8PcJsVgskuGPx2NdXl6m79O+nZ2dZCibEJ9E\nTDa/b7PZVKvVUr/fTxOaySwpGVwE2UajUQFi2uzG7u85ILHwub75n78fAZff3VYY22azqd3d3TRW\ntVotgZnbGP3ZlF5pv7/nC/bOzk560Tb0wvcYm9FopMlkkha57e1ttdtt9ft97e/va29vL43T7u6u\n6vV6stNIQvhfvV5PugUcrq6u1Gw2k94jIDHeOzs7qtVqGo/HCZRpl9sDNgRgjEajjeg3vqK+o/h8\ndtJGv+JCtFgsEuB2Oh3t7+9rf39fu7u76TqAH+MzGo2SbqfTaWUutFqtpDsfB/QL0PviRb+cIE4m\nkzQ20+m0MgeYt6vkXtBFuQAoiuA9vxnGBehF9N/aWt4urh5ueKsGyIHXgWR7ezuxFQarVqslBoBC\nMFyAivY4iNAXGMJoNNJ4PNbV1VXqq7P1TYGu6/j6+jpNHgaPid3tdtXpdNTpdCqGhJ4xnshyIwN2\nj4T/O9jmxiAutIgz28h2fTL6JGNxZMzdk3I7e6w4mHmbc8yfye+LP/qdzWZpUk8mE83n88SC+/2+\njo6OdHBwoL29Pe3v7yfGiyfCGPq9WHTiYuAM0L0YZ1nX19dpvjGOeJ/o3T1GFjwA4/Ly8o4X81jJ\nLcg5wRYZhzivd3Z21Ol0tLu7m3TVbreTJ9Hr9dTr9dKC1mg00thcXl5qMBjo4uJCs9kseRToCN1u\nb2+r1Wolj8ptnEUfvaFTJ5HMS8bs8vKygon32e69oMugR+YSWSyTPrqbDnZ8Ng44YBBXylUvD22w\ngrdarTR4dJo2ONhwbb7rbcVVuLq60ng8Vr1e12g00uXlZdJBXBg2KUwWAJdJ02w21W631W631Wq1\nErvBaOmTg+46/bmBMZ4+Vj6mqzwNJIYUHODQawQAZ9nYAsDmi+RjBS+NfjoAOrN1Rks7AUhnUUzS\n3d1d7ezsqN/v69mzZ3r69Kn29/crgLC7u5uAVdKd8Jsvdoyfe2CSUgip1WpVFiUHXvQM62X8PAyB\nh+c2tolF7T4b88/lvuf6Zo72ej0dHx/r4OBA/X5f/X5fvV4vAS669RAiYYarqytdXFxoMBhU3H7X\nNeEs5jQeC7pxL40Xn+MezBdJd0hLjrhEuRd0mQgRweNkogHeWIB0e3s7fZ+Jd9/K6AzN33PAZfJ0\nOh212+3KJI+sy1fX6Dayenk/MXzctk8DdGl7BF2YbqvVShNeugVFd8kciKWqgUdd50JF7soymVd9\nPxfHdXuIRixVWWYEXQyb7z5WYIsOuvSJxdrDCHyW/zvoTiaTBLqdTke9Xk9PnjzRs2fP9O6776rf\n7yc79AXlPlDyxSCCMPa9u7t7J6fi44fOAV3ayjVguu4ZbULWgWwOaHP/i55Qr9fT06dP9d577+np\n06d69uyZ9vf3E/i6rXtYjrkD0x0Ohylvg8zn8wS6eK+EsRwwAdo49h5ScM+Se9OO+7yIBzHdGAB3\nGu4rSUR8VzKfgdE4E44D4itfvA7/i2wpMj5nb/69yHwBU/rD33xmMploNBrp4uJC3W53YwYbxQfd\nB9ANchVD8p8u69hGHKPYBn8vB9we54rMNK76McSUewH0zsgeK7lFKLYv5xYSOpjPb5OvkhLDevLk\niY6Pj3V8fKyjo6MEuPw/LoA5+47in4keX0xOX11dJfaK7cak9vb2drIlWDE23mg01Gq1HqXbVYC7\n6nOIh+bQ0+7ubgqffe5zn9PnP/95vfvuuykR1u12E+lYhTXu1ULEAEu3VZJn6CQXGoMAsMiSPAXE\nR6NRJZHGtbnOffmIB4cXAFi/sAODs1cPI3gMUbp1Ix3E3QXLxSUdNHPX9RhxBBBvC5MKdggTImnF\n6uZJQQddEj5vS3wxQ98OujkAyV2DPj4kxpYDXge+HEOLAJu7Zi7c4KEF91Y8qSTdGvBjhYSuj71P\nUBK40UOjXST5cCnb7bZ2dnb07NkzvfPOO3ry5In29vbU6/VS1QwhBe+Pj0PUt/8eGSDvMf6ejCN7\nDwPb2dmpeIGSKmGRmGPZ3d19lG5XMdfcZ1xIfJOM3traUq/X08HBgQ4PD/WFL3xBX/jCF/T8+fMU\nx/XKGpecl9BoNBLoulfA5wFKxzMH2+hRXF1daTgcJvY8HA4TAKN7MA3C5vfMyYPCCw6w3kB3t2NM\n1oHR2Zkz58hEc3Evv44zJp/Afv0IHjnGTfvc3XJFU6aytbWVEmrEgTbNdB3EIjt08Fm1usfFJV47\nJ5HR+nU9LOT/v4/RcN14fe9DLonnicnYjsdKjG9jH+5RuE1g00w23lssFmo2m+r1eur3+zo+PtbT\np091dHSUYu3u9ub0lFvc1rnkOY8RvbndM6c8KUw7mGcxvumVL28quZDCQz7noEio7PDwUM+ePdOz\nZ8/0/vvv67Of/ayePn2awNbJV842fIwBdccp16knxHJ4xvz3OO7FxUV6AcAA72g0qlTcYFfr5F7Q\njSuCNzZOdNxHX409Sw2jhEk6KMNK4mQgHuUx3siSeEWGGAceg0SYXKxY/l13M4jrbCoBsUrcBXfW\n56EPBwTiSr7wrauocFD0+CvXkXTn+/6dOLFyC0YOcOMrF356KLB/EqFWNYaXACrpllV7VptaXcrH\nWq2W2u12Ktc7ODhQp9NJbC22O9pIDDGsC53kdIhdw6Y8N0JsGqbtHqUDtbeBmOUmJBc+WdUn9IJO\nnzx5kkI1T58+1dOnT/XkyRN1u91KvN+/G7En59G5DnN6Ry+5sMLW1pam06m2t7criTNso9vtqt/v\nJyI2HA6TrZCYvU8eBLrRJcvV3vI7oOvAi7FTHzgej9Mqh2H7hPCYIqBNtjKyXAdfD33EgZFUYVMY\nMu4X2Ux3QzF4gJnSnbcl7kY628y5PbTRg/YAgFcgIDkWiusdDTSKf9fbuirMEEEjB8Kx328LdCPg\nODt0AoGNRXc2usAHBwcpmw7o+hjkPA8H/Yd6JHHsnXk5eDHJvQzNPRbsKRKmTYTJ1jH1Vf3BPlut\nlo6Pj/X+++/r+fPnKUbOopcD3Ti3Yxgnt6DFBcHtPUcUXN/olOohj/PCeC8uLioLtKREilbJvaAb\nG+WrDh3y0i1qSV0hDhqAOAFvyp9w850J+fUpFeEFYPvOHpSeqzJwwAZ0Wcn4GUvgcgm2twW6GCMZ\naxYbSRXG7WUurrdoQOsYx31hCW+T//T33U3mGjlG6wt1DCvlrrlJ4CXp5KAYQzQspDCc6XSaMv1M\ntlarlUILuYRZLiQSF/yHuN+rvIT4nocR3P2OyUiuz9yo1+vJlh4Luuv64zpweyS00G630yJ2fHys\nJ0+e6PDwUHt7e3dKCVeBI/fy6+cWu8h2c23MAbMTlxgGiwQQJuyVDOvkXtCNRhoZDQyBMhpq6xzM\nPMtXr9eT0vv9vnZ2dtJk9MaigAjmbNn01cXjur6iR4bmLNCB1xOF3ud1bvGmxAfdJ7qvnLiDrksM\nIDLYTyKrjJD3fOFc5UY6c4o6811mqxYvb3cu4/8YoQB+1SSj/Xg86LPRaKSkWafTSVt6fQNOBIW4\nkDjQrAOomHDL2dwqYe5hJ9g/1/J7cJ9c+eebyKoFchUAogfCNGwm6Xa7aT7HBYif8eWJc36umwe5\ntsZxiwTB8xD+f67jG04kVUD3vnn4INB1JeT+D1D0+/3kglGkjOt+cXGhra2tpORer6f9/X3t7Ozc\nqaejsx5L6fV6lc0BXnrik2CVC+uTwFmOg278fByEhyj0TSUyAWou8RR8ESO8cF89YLw+knN9c8Dg\nq3mu5lTSHfa6KkHhnk6Omfv9NsV0YaTr9OS2gk1QTtVsNtXtdnVwcJB2QOXK0OLkRdwu/bNxAfPJ\nyivnEUTb8/bwWfIhOdDFnnzjxJvKfaEEfvI7DJFFjM0P3W63spEkAq+Pjetu1f1XgfSqMct5ErFA\nwME2EiQwCqL0EL3eC7o55kJHGo2Gdnd3tb+/r3feeUf9fj+xgdlslrJ7ku4kI5w58HIjI4SAG7K3\nt5cAF/cvAi0rP6AcE18e+3WmCKj5KuaA469NAUJOCLlQlxh3GHmpi1TNaMeqgFXuuq/aXhrH9WLl\nQnSXImg4kEYGFd014u8eForlWjF09RjxA3xiyWBu4tIPT1a50BdJ2bY6MER9o9NYAplzfR0EvICf\nJKt/Lsficy/aLN0C4GOE9jsgeTu8757n8U0+8ZwLj79zvbhorWLX/v/IYv2aq8IVrmsPveS+Ez/v\nCwt9XCcPBt248mIAgO7z58/T5gE+z+ETFD/v7++ngmcP8MeDJer1ujqdTjo4hINEYC5e1+kxKlad\nuIoxMAwsJWEMqLuXDuaskB7CyLnbjxFnJTBdvAEWj/l8ngL4Drq5RcEZTZzQvvsG9hnjnRFscu6u\nG3CM07vr5yzLdxB6oio3SbzNjxFPhHlWn+t7W+mLg+4qNxUdrlogVgEv+vRxcV3G77iXgP06I4ye\nAqCeC9NEV/8hWfZ18hDA9fv5ztEIutFjjba7br7lxsgXv1X2lANRcAuSwT1jCMI/54UGtVpts6Ab\n3R9H9V6vp729Pe3s7KR6Vt9Hv7Ozk4qfj46OdHh4mK7nO0Oc7RJ+4NSmXq9XmUQoxXfFMYkBcHcd\nHNAdgFFqdNlj8PyhmxMeI3gOxK85RpJ+ejw0uv45o42GmgMNB9rcQkXlhu9K9EnvO6I8zu5eQY7p\nejLU2egmJe5680UgxlK9ptUXkTj54/dykzoXl14F4KtecUHlO/V6PS2WHjP39vi9cmMq3S0NfBNZ\nxahzffUtzYw9447+ib9HG45kaNV9pGoMdtVn4gLHezlvy+dFBNvIdKWHeREPBt0oFIvv7e2p0Who\nPB5rOBzq9PRUp6en6Wi6Vqulp0+f6vj4OB0K4ox4Op2mKgZnS5wsxMroIQXvJGAb3VSPIQJYrlgf\nTB8cBwgHhGgMmxb6znm+LDr9fr+S6PNJvqog343Kf/cJ7QtXBFFOOhuPxxoMBpVzWL2+03VCLNpf\nLILx8zEHwDZbL4l6bKJHqsY8mfS+QEm3u7akqq17WSKLfWRkObv4JC/Gx8cUVsjvnKKHDfhZAF7m\nGMvK/G829URAfozkmGh8P7JwShRZdLHByWSSTgZDl/TdF+m4UQKJ4QVvlwtzAXIX2xkrQNzD9woi\n8ioAL9+POZdVci/oriqTyoHuaDTSixcv9O1vfzsdb3d4eKjnz5/rM5/5TKpW2NnZSZ25vr5OKyCT\nw9mSr4woLgIJrpIbsm+BpB+e5JGqO5bcbXbW5izsPlfnseKAhG77/b4uLi4qLq8bSATdnFsVV3ZA\nNzIGFqXxeKzT01OdnJzo1atXevnyZSUpGtvLQkF79/f3NZ/PK4e/uN4YL8AdgCAcxQ6qx4ozRtrp\nwLtYLHRxcVE5qg/W6JM+hpci+ObitKtikavAgM8A5Cz6AK4fvuLA4Id4e9zf37u8vLyzZX8TXsWq\nhcSBjN8978J8xyMdj8c6Pz/XxcVF0p0f2drpdDSdTtXpdCpEI6fDXIjL25Jrr1et8D3PU6BPX9T8\nzBb6FjcvrZIHn6frE31rayuxlL29veTqeOyJ2KRnJ3EjIogTG/aAO0pxhuEMNufC+I42dpnFkjV3\nZeImDyan76NfFVbYJGvgerhhklLWfH9/P00kZ7v0wYHYJ74DhMc0uReg5iEY9Hd+fl4B3FevXmkw\nGCSD8utiFwCox1Dn83kaT78+44qNXF9fpwoWFhcH9zeVuOWT8WVSMv6xTAjAdRc4hnCwCewtht54\nRRvKhTZ87CTdGT/fdenzgDN0XWJ4AqYOkEi3CeXHyiqwdfH55f2BqM1mMw2HQ52cnOjk5KSiM9pJ\nfqfX66XzpEky58iQJzs9vOh2HmOytNVDCnEzSfQmYv0557Tcd0D8gzZHII1GI7n9lIYBCmT/eaQG\nSqL8ZjQaVYr6Y8bS431+9q4bKp3mIOn4Amj9FWPG7layIYK++TmrHlZYxUw2wcZc0EOtVlOv10vx\n77Ozs0pMN4JSbsMEuoVVRCONBukL1dnZWZoEg8EgnSnMvZ2FUZXC9TG+Wm15kDxsxSekMy6eZsAC\niRFv4skGvgHG7ynpDhP0igUWhJjsycWD4wYbtpDC1Pys51hbLVVBN8aQ3dV20PcFznMQMWSEd9ho\nNCpbWhmTTUoMmXjfvH2QmcViofPz8+RVvX79Wq9fv76zixWPiaQ6ocq9vb2K55JbzDzmCnD6EZ2x\n5t0xyCUCtm+mchsbj8epVHadPIjppg9vbaUqBEB3b29P5+fn6TR66tWI3bZareRCjMfj1AF39zBu\nd+VyAW3iJu6SelB7MBgkNwXQZSLhsnjwHsYgVUEX1r0qcbZJhuvik4yF7fDwUB9++GEWdOk/8Ve/\nDnr0J0545YcbEq4RWxtPTk5SbN5BFwHMeYQKT7KQlNoDiLfb7Uq1iDMz9uA3Go3KuRzsZ3+suFsu\n3VaweGgrxuEcdCPT9YmNDmHpbG/nxC/c4nq9nhYdD2v4oofb7TaQc4FhrJPJpFJyx7VjGMftnuqc\ner2eciWPEZ8XkZjEBdbb75VKZ2dnevHihV6+fKmXL1/q9evXlV2q6JNHVR0cHOhzn/tcAtNOp6PZ\nbHZnF5ukCpP18WbrLjY9mUwqO1397A0PPebYLtcHyH1r8Dq5F3S9lq7b7Sb2xUqDQllxMKL4Nw2l\ngTAxNj9QVuanNsEWPGzAisJhxSiPTvPAOe4LKyNR52CDa8wkw2gZVD/oJgbrc3G7N5EYpsB40Qss\nkoVoMpno/Py8cnZE3FzioEtSjlP3uVa833Q6rZyk5M8Bi8+gA2z9UHXYM4ucdPtcMUkVlhMTXLVa\nTd1uN7EIFs9vfetbj9KtAxvt8QOMPKQh3T6pwatHAGm3Hfe8sDlPdsbQjqRKpUZu0eaz2JTHQ33i\nx4QvRIH/YbcwOD6PPVC61el0HqXbXB9i3oBFjvtyHi5zleMRt7a20tMi0NN8Pk9znLAbNvrxxx9r\nsVjo6OjozkLjhwP5QshpgTzok8dwXV5e3jlewH86IfREc0xW+hb9R28DpgKBjQ2cCgQL8BhurLUl\n1suLTkO/F4tFYju+v5097pw2FDOIk8lEJycn+vjjj9OTPV3B19fXidUR3mBTBKDgbh3gHkEXd8Rj\ndhhXZG2bFNpEKAfX3UGX2JEfrhxdOUCXBBeTzWPmTF5iazBb+g1TI+6OLbC5xZlL3CiB3jjPAP37\nlk9f0Jk05+fnOjs7e7QevVyKCcNChc1gLwADHhr9gzh4JYxnq1mkPOfhbFVSqtCJ+Qpnqe6BRFtA\nog16whehAgDBFnDPPS66SXH273aILQO6tVotHRgD6G5vb6eT2wC42Wymk5MTvX79upIcvLi4SGPC\nAUXoHHIXn6QM5mBXp6enabHl8UvxPBfiyCSG9/f30zzxUJInMP29dXIv6MKSKGGC6Tpw+SrtjCC6\ncYPBID0C2d0qysLioTOR6XpQm1jQq1evkuHTcZg2MS3Ybgz6uyuJsUY3ArfX++QF9psWZ7qEBtBP\no9FI8U4nHunvAAAgAElEQVRYqa/kMf5OLM+Bxg9s8ZekSkwcA3KmwmT1czAweO4hKY1BrCMFlGL1\nCHZDvJJ8wGMlxk5xBf3lcVgmGxtTCAXAHvGosAXY1HA4TOBCOMInqCdm2KYLaHricZXXE+3DKyho\nN+9TR+1kaHd3V0dHR+kpF5CcTeh3XaiN9rvXyhhLSnF0173nHLA7D8NMJhMtFstHgB0dHSXi5MAL\nqJ+cnOjly5c6PT1NgEsJJFuh/drMrVqtlrzo4XCYsGF3d7cS1lv3Wif3gu5nPvOZ9FA4fhKndUbI\ngMdaSwyWkiBPasQB86ysdyBmvQm0u7sHcKD4WHTNJJjNZtmHEjYajUqQ3UMa7p4y+XyTxmMlTq5a\nrVYpwyK2K90+DYEkFHHbmEF3tnF9fa3z83NNJhMNBoNUkhafOYUuYrw7uo1Mhna7nYDDnyPH6s/E\nif1zJh6TS4QuNgG6DlBMRkmVxFn0DrAJJw3E0GHHLBQeopJu7ddZL4DDNakXZyxZuHLzIf7tYMt1\nHehpE9/d3d1N4wxrw2Y2kQTOJZm596q2R1sibAAwxsSmh2uwJXChXq9XQnCELmDTZ2dn+ta3vpUA\ndDKZSFI6QAt2yzWoqBiPx5XkrrSc+xzvGDcpeb/BwHXyYND1rak8KsSTUDSCxIKXU8BAATQ3dh8k\nj9vmauHcVXFDZUAYRGfFgC4K4fP0A0bA4OO60z4GX1Il2+2JvseIJx34W1IFdNk+7YsHE5YkDXr0\nfrvuqQao1WrqdDpaLBaJBXmZDu1xVoauPWED6Hodrp+izzjzfe7tQOh1sPyfkMqmQdeTakwMt0P3\nerzCwROXhMc8IQkoeOzYCQLgyPsO5l4adV9y1vvi14UlAroOeF4B4+fUurf2GN3mhHtHm/bQC/9n\nvo5GoxTWwv2nLpcXwIpt+xxg81S9Xk92Duh++9vfTqGE2WyW6uC73W7a8cr1a7WaXr16pdevX+v8\n/DwtstgLoQyfJ66LjYHu/v5+GjB/rlEu1uQZQ9iFB/BJlnmjUBwrDoFr75jHX4ktEnNxto046HAP\najT9xWSIgXjP9Pr9iJ0x6G8jpuv99NPYjo6ONBwOK5+NoRLPGPuiBcvzsina70dJklzyGJq7/yyo\nACUeRaPRSBNmMBhUakgdzBh/PI1ovExM8giPFa+XJVbvYY8YCuM0vLOzM718+bLCLNFFjM2ib3+q\nA+DmSZlceIHxdpLwEPCNCTRfzMiTOMulcoXFZJOSq7SIgEt74gMmCd+xkPi5BfP5PIWx+A4xYUmV\nUIkfg+oJR2wJncznt3XjW1vLR3GdnJyksBHvOYNdLBaaTCY6PT2tJN3crnyBjSQqJ/eCbrfbvROr\ncrDJrXgxtuvKiDFRFOObEXIhBBgFsaF+v6/Dw8PKcWpeUeAPivPYMwYLuCNcA8DwUAarIsYCID2W\nLawSnzjc+8mTJ+lQbndRfYAdIPkffxMmYUHCa8DVIqbuu8EAKlxmanUJswwGg2R0k8kkZfJ5zw8D\n9zMl3EC5vrvqAMpjJda3OnONoRhK5mq1WgJN2A0lcV5GRmIQvUyn07Rg7e/vp0UT4MWu0KuXicWc\nBYtVtAnvF+wYO/XPoH/i79TkeuhhE/mIHOB6e71ChVpbjyez0QZsoUzSvVHPP4ATJN4ODw8r5Z1e\nk0vowTcXOUm4urpK+SCYrz9QAT3j1bMVnjI17ACPxzHyPt3eC7oEt+MrZmD5HXboA+OZfmetdCzn\ngtEZ/46XGPV6veQ20QYv0fHYkLNewNcZCO/DdKl+YKLh5pMIgBVtYtdUjh2gFwwR0K3X68nl8XIo\nfvdFJ7pBPrHRZTwg3p8cy7VI1AH26HQymaSJ72Gc6+vrStE6Cxxhg263W6lsiczTF7vHipME13OM\nObIo4UqyWMxmsxRLB7z8AH1CFh4zJh7o21h3dnYS4KJbL61bxb5X2YvX7PI712CxY0EF+L2yZJMJ\nYAepaMvYkJ+1QXtgkPQD0uVeqNff0lf6RK6DOel68wT9wcFB5ZwE2nVycqLz83N98MEHlXNevLID\nLCPp6uPmtupVGhsB3RzgMrH5CSvzeGxM5niCxgfe3f5cvMuTFO7yE1NkkJ05uDF6nNcXB9xE3EbY\nZczW43pHAIOhvQ1xo2WB6Ha7iVF5aQoT3xcAmBufXSwWyTWr1+s6PDxMhw/h7vvEcODz2mdCFpIq\ndam018uu4gtjhnXRRk/Cumu4KSbGvWLy1m3Yw2WMre8yGgwGajab2tvb0+HhYWI1Pv70fTKZaH9/\nP4E0NujllJH1rnPNoz0gzENCBp5wYlHwiiJAGdKx6dAY9wGYsDnfzg5IApTsXnVCxE8nUfQHkkCy\n1Xc6ekIfT1ha5kbIJXlYE0+aqiB0dX19rdevX1fsmsUMOx2Px0nPEBgP+dy32+9BT46ITNaZg7/v\nscTIwBgMlOOgS0NhHN5JNyoGl+8Aul6QzHVRirteHqPjf7jasBMGgDiuB+l94XhIacibiHsCDrq9\nXi+tuCQqnaENh8NKjSw/GRvCKc1mM+0kpHbXQZcEhRs6jIPsL6Dh7JnvdzqdVJ60v79fSYKQE/DQ\nDFloxniToIs+I+C67fnkcnDyAvtarZYOa1oFugDC5eVl5WnBbsN+b0I20VuMn6NdHiv0+YgAejBL\nB12u4aC7yfhubA9zdWdnp/I0GUJ0hAQ4GMk3GVC2iB0CjNSG8/24KSeC7mKxSKFBz1UggDZ5IaoV\n2Bk3m93udKMdhBZHo1Fi3fTf58x9+YhPBLpRwR5OAPW9zMurDhgM3uNaAByuvgMoRuSrp3dwd3f3\njru0ijHwPVcg7JXEn6+sgK7XbTqIe0jkbUhclLrdbtpm6CU/JKwADI9jS7dPo/BdNwCuszHXKXrH\n4DxjXqvVKvFyxDe38Gjt/f39dE+vjnCWx1jFeP8mmFgsgYsLGvdxDwlw8oNNsEdABH24Z4dgV8S9\nHdjd7t1L9FBQlBi7z+UvXBg313f83qrvPlYc9BuNhvb39/Xs2TM9ffpU+/v7FeD0YxpjlQ3VBsxV\n363qZ/HGxdrzPpISEYCsxPNDCAkwxhcXFzo/P09t8jlEn1yX3JP33ctYJw8uNI2JBwbOg9wkRmL2\nPF7DwwfuPmCoXrjsoJsDXk+kSXcP3nCAdZYeY8uuNAbZ3WMeze0xqE+jwNxjYjBGwN9j34AhJVHR\n1STOCoBjwG68jCmuMrr08iTAxmPvvnuu2+2m3U9UfHAt+ivduvFel+32sgkm5hMlSvTUHNQ8vECC\nxRkW30M3Ozs7aUcgCcb5fK7hcFg5S8DH2j0uTyLnWG+MP0fWHpl0zIV4jJ7PPxZ0Y5sYSxKI3W5X\n7733nt5//32988476TRCwlaEGPCQiZFjn9hwrkQuLiYxbIk+vMKGJDQA7HiAR4CXJqmSNMaGPVeF\nF+PVKJ53WicPPtrRjcYNByXSCD5PUia64HzXM5Fcx8uMUCLifzsQOKuTbuPH/jefdeXE5JorbD6f\nV84soE45lsutA8tNSExExGfE4SXQZ1/No6E6+HrpjleJOJDwE1DB6GBu0u2pc85gePk5D3hBGHFk\ntu5eMiZu4G8qPkFXLW7o2BOqvqGnVqtVPAU8Mia41/bO5/OUiByPx8lbYosz9/NkET9jCVIUXxRW\n2buTlJyNcv0Y8tiEQLQIhR0fH+vdd9/V5z//eR0eHiZ8cNAF+HK24WPj/XAPlfvG8FFcVKg0AV+c\nlER7l5aA6lvs3f7dawZ0aRNz6NGgmwst5FYfTzZJt1tvfaeUX8ddIN6LdaH+eRTuAxdDF7TLr+nu\nlhuix55hNb4llqoB4p6xNs/b9bYEHXjNp7vrznjr9XplofPJ5clBFkhnyNGLcd1FQPCYbK1Wq4CR\nF6r7LinGx+N3vl89nhbni+3bFg+f0Xd2T+JFxYOHfNeZ15f2+/07MXWqOhgrT7Y4y435kty45GLT\nMVTif0fi4m7x28hHYA8HBwd68uRJ2vEYGaX3070sgCvaovfbGSqCd+T5Fu+3e7q+WDIWXHs2m1Wq\neHiBbwC253SYB1HX6+TBj2B3xTjoRtcThRAu8HgLCoirrZdzrBIPEwAgzoq9VImYSgQeB12vsiCm\n5OEDQBc3mfvFAX9b4osO7pEDm+sdg87t5HO9uX4iA8wxBkkVFkB82cMYHptzu3BAdwDyU5m8pM/L\neu4LuWxSvx7jpP9+HsNisUhM3vvqrizeg7RkVbAkX2gYKw9T+MIUQUiq1tV69YGUf2pDXEAcqL2f\nEZQ2IVybioQnT56ks5Kn02nyBiJpcRunrw6evoAtFrcVRgC0VGX7eCkOxJFokIRvt9upTDD38pgt\n98Ob5PFk4/G4giuemF0lD/LhfMCcOeZcWG+gryARdF1JAF9cxX0wHUCZ1LgDnBJFPNYBOccgiCkz\nOA64Ht+B6fr5mj7AnwbTle6e9Qvo8r7HrBzUiI3Tbt8hlQuTRJYBs/DYI4kJssHOInIusodyPEPt\nB0m/LaabM/5oX/F36ZYEsEHDz1iNnh+6ofRod3dXp6enms/n6dBwANprdwHddYDpY5KrBqIN8cX3\nPIQT5+UmQdfxgQ0JR0dHlTNaJFVsI8fYc/2NiWH6733xEAR99goqdM9YsfBgy7GWnzY5warVamkD\nzXA4TId2+VnNOdKSkweBLhMqBv3dfYxuaeUmNwHt6Cq5+8VRgjFr6DHZmHBAeR4bIsbii4Cz6gi8\nccEAVCnAbrfbqtfrlWzqqkzz2xB3853t5thonHgIY0Xc1Z/04GPoTAhD9CJ1wB0dAOpkjZkkPhkY\nd18M/GQ0B93IMh4r2JdfN05e+r0KzAgfAJCx+iYSEoCXB4ryPolLSrk8nMG1kFzMO84vJxGrQDv3\nnbfhpaGnWq2Wko54h364FJ+hb0hk94AZAOf2755zbkHis4vForKBic856WAOxJ2KUfx9Xziih+S4\ntU4eDLqR3Ua3iI4xCHGAWfG8g36ATHx4Hvf1CgcHXa7pYAjoshJ6OCQyVO7hoOt1jTnQhfnRtk8j\nzOCrOgkI32Ek3SY0c4DLhNja2qokvfyQFPoRwzV+sA8hIxjf9vZ2hVmjUwAChuGbDQBdL+Hxc0ij\nW/dYybmK9MX14z/9d4/Z4lWtc/GxVz/8nGv5gdgx0cOEjSw1ltFFgM8tEn692E6fJ5sUn2d+alfM\nITjoOqv09mDXnIh3dnaWDn8CTB20XVdupyQz3Yb5v5cwRjLoi7KHh7ChSFCiV8//1smDHsEu3d2Z\nxoXdOLwB3DyuvO5muqvJiuRM0hm2g72Drr8PsLtL7Z/LgRL/91USgKKOlcFB6VHJb1uY/L4AoUcY\nu//f+++g6+GF+8IlGBv/Z5KgI5/EvohhLxgzk8ifI+bhhRha2KRuPWacY6ex3zGk4qEAGH5kWHHS\no3uScNwnt2EhJ5HlxoXCgXddiCQHJPH/mxYPt3iZYqxxpX+OD/wPuyAu7s85vL5eHhrvm5UkVeKr\nYAbJ0NFolMI6eG4siswr10X0xN0m78MPx8J18qBHsDv7zK00zgw8xsf/PGPtZU1eD0khuWcKPbwQ\n44bu1joQ+R5zYrV+qhWDn2NghBX8RKRYKvJphBWiq8l7DpIcsELs0d0f9xCchUR262wpTkLul/NQ\n3JNwu0CwF6+7Rsf+08MKMeG6CT0Td47tjgw/MkyYPJUrHtOPk4v2O5lA3F5j+CoHOL5g+ZzzxSF+\nP0oEW18YvCRr04m0eN1VXgL9gPEyLnyfg5N4DNdisUjvxSQr17m4uNDp6WkCZAf5Wq2W6u6ZK5zX\nkqv5jT9XLay5z4In953Jci/o5hiIN8ZXAIzMC5thO8Ty4iOKZ7Pbw2OoOQUgIzD4hIkhCI/3uPFT\nRSHd7iKr128fGe8hDhIB/oysCLoM5Kch0bgcLAFd307qixNxdP9eLibOK05CBwUHF7K5XkfrYQQm\nt4coODAnMtu4SG7ag8C99BIvJwURdNEXJWCcGRHrmZ0FuR2xoLi35p5ajJ/nxjo3wX08ckw9fj93\nLe+vhyzeVKJXFAGJvnss17fq57wGQNfPtAZ0OTaU0BSedb1e1+npqV6+fKmzs7NEmuJTTggPAsA+\nHpHpRu88Nx5Rz3yOHNU6edAj2KOReTKBCRNXT2KtKNKzhNFYaChGy9M0GRwUxK4nf4TPeDxOz0Fy\n5sR3iRc66200GulzMKFarVY5rMV3UUV3zgdmU8L1Vl0XUPXdMb66umcRFwdPZsUF0mOvPELaz4bl\nGpwshp6cwfg1vQ/RbhyQ4ySNDGYT8XI/0o/rOrNxe3UA9cXXdwHCnrzP7jnR5hhDZKwckFxy3kIO\nYLHBGFpwWcWgmRu+iG5S3BYhMX7I0jrS5m3yB4Z6uAyc4MBzX9x4LM/Z2VkCWklpDnsuCjv3RZH2\nx9CCezG5RG98ORFcJ58IdKkUiDTfJ5N/T1JiZDytls4jrICAsn8XdoLLwC6xVquVlMBp/mdnZxWj\nZcAoDWOHEK4i7eX8WBj29vZ2enIubYhu3SYlujYucYJ6ogL2gKEjcXFYZewRgKbTaXowZSyd4f8w\na3cT+enx8+jGRsPMuWmug03pGZbrffZ25iY9oEuIyb2dyFI9Ack4MCa+U4kEUI7Fr2L2cRGLgBuJ\nyzoSsFgsErlw7+KxEtku5AaS5Zt0cjaxyjVnJxj5FL8P26wBzkajkZ42QRkXIYXFYlHZBEGcndgv\nCyJtoB/OWqPOVgEv/QPk18mDQRfA5WecRH5T6bZcB4Y0mUy0tbWVQI9BcxfWs9lcE9Dd3t5Wp9PR\ncDhMTBcg8Ec1e/0q7IR4MTV/KB/2t1jcPsSPWB7PTIosww38bQBwblJyb9w1z4KjaxaOyMjcSAAF\nWCzXZ1L6Q0NjzW29fls2V6vdnn+aC4FE92zVaxX4cr3HSmS6q65LewmHUTzvT2LOsfeoQ/rg3geh\nLg9teDtWga63bV1YAVl3jehNbgp0aZ90S7w8Oe5hxpxX43bgOR/CkHyHxdOvD540Go07Nd/u8dJG\nQgnz+TyFEuPhNDm2615CBF8HYfTPHF0nDz57wZmuhxScNQHOuPX+gLmcW8R3cetjGZJ3kAE5Ozu7\nAyp8FhCIAEA7cUl8EgJWzWYzPbyPHTVUL8SV620A7kOEAaXsq9PpVGpq+d0FI2Uhm8/nafFrtVrJ\naC4vLyug67FygJ5SIMbWQRm9uETXOFZLILl47joQeajkCusBV082+qE/i8UiPVeMhRfiQPuZ9CzY\nkfF4QsyfzydVn+4RwwCI6+E+sHWJi1lk+Nixx3c3JU7OAMBa7bZqAx3k4qV8hyNKOe0L8WsuFotK\nyMfPr2C+svHk+vpap6enFa+O6h0IFyGzGIqLjNdj9l4QwNOJYdX3sVzpgaAbwwsALAbtzJcVlJAC\nYMiqFCcooIt773vy2W5H8s3rOWMJWax99AnurJm/uTff3dpanu/5zjvv6OjoKB10E7e0upG9LVnl\nKrI4zOfzFLuiDhEQiIM+mUyS/rxKw59ogBERG0dX9Xo9nYfb7/fTY2j4juv/vhijMz0mn3SXJfp7\njxUHXQc3mLovYH5uMAcc8dSUODkvLi5SiZInFwEBX0QcLAB4t/2cRJ2sq1iIeouggTjL9t83IQ70\nXhEkKVUOQZxyfYSFY6dUI8B6Y5tJhHFtQkC9Xq9ia4AuCw5zmTHivq7fXK7BGa6XPAK8voCzyKyT\nB5+9kHOt3L3yz3gcDYV5p108lsrgeF0n4YPt7e0E5Ex4XFzfwutbkyPIe/vciH3zAE/f9drMnMvv\nPzcpq0IXhBnoLxlaSms8EeTfjaszmd/BYJCqIPi/PwrIFzKYipedSdWDRpzBRKC7r8wp9nNToEv7\nfGH2EA07p7w00EsWr6+vdXZ2pg8//LByKtbFxYUuLi4qhfe+cSXXJ9rBpHf7XAekq66Ve3/VKxd7\n37R4WBFgwmZiuVxsM3PSPVxnvpIq8zpuMGHuEjrzUAReNoDqOybjuBB7jqAbt9bjwXtINc7NdfKJ\nQNeBN+f+SLf0HDbhhdKxtjOXIOB/3MfBgJevLp4w8zbHkiD/OxojCgP4VyVO+K7H996GrIsZ028e\nJ3RxcZHOb42g6wAo3SY7/NE7MVng8UcAl0w+h5THjQLeZkl3Ft1VgOvvr1rYHiMeOvJ4v8ds3R31\niUcckacJ+MIOA/NEEQX4vk062jY/fVLmQi45rwp7WwWc0WVftXBtakHz69FmbIIFHv34Ah7HPBea\nwfYdLGOMFgbqQOn3h4g4AFNCiO1DLsCPXOKX68WdlHj0cafuQ0IMn+iUMQddByz/jLvufsgEhu9K\n5fu5Mx1QOCUe7Drxk3148R1XMu2FIeYqKxx8YUDs2loVf/a/33aIIXcvFgg/TR+Dge3mQNcZBVss\nAWvXA+PBvdjBQ+XI3t6epCqwRl3E7PR97DYC7yaZLvry8IY/KDOeular1RLTcvaFO8th2zAmZ19+\nTm5uEvrCE8Ntrgu3tZxXBcBE3eZYrksMs2xSmEOEVGL1QiRB3qZcRQOfQx/OKh2wmd+esCNU4eVr\nhC1gqJKSLfjccvD3CicPJ3iZqYP2xkA31iaiqMhwHASjolmNYrzHXWYHXF8RWdHcXZBus/K5gXCX\nwoHZWYInlXyXChURPkF8xY1G8rYlNzlY0PxpryxqOXaLnj3uGIv1pVs3nIWn3W6nBwru7e2lUjUm\nfdRF1E+s7fYxc6DPMeFNgIJ7MJF5wmbxplwPtJNSw/F4nI5v7HQ6dwgHNor7io4JNaAzkpp+JKcv\ndm5v/IxkwT0t/5yH/NaFGtyGHiuOAYAPIZmPPvpIX//619PTGBgHxwZPaPLT++SxUewD3fl855qu\nn+3t7cpTIlgQiONy6BLP/fONEg7o7kHG8kPa69gVKyJy8qCnAUfwiQPohsPnPIZLo1kteEw1BuVg\n6+6WAziGxSrFKgbNj5OU660CdE/I4W6SqWbHnK+irIIxm/lYWeUC5sTHAdD1J0BgEJHd8h03Cow3\nxqSobIAJ5kA3xvTdMN1F9M/F+sZ1oLoppoue4q5CX1zd1hAHXTwC9u5Lqmyy4XtsPJCUdAwTpk/M\nAY9L+uSN8yzqI+d6I7nFL/fdh3ofDxVniTy04PT0VNPpND3O6t1339Xx8bGePn2aBdsYjqGPHpb0\nA6kicaI/ALAntOLZCoyBM1cv84phmhzo0l/awe/Mn7cCuogn0nzyOsOQbgESij8cDiuD72U7DrI+\nIO6iOUNjcnsiabFYVNgfoItS6AMxHeKWuCdeXuUJGM/O+iE9m5SHgA19IhnEy7fZum5iUtNLpRBC\nCbE8jGv7yfm5onF/xQy6x+Rie+Li7ezisRLZvd9n1T38f5eXl2njDaWD6GFVKaEvzLF23Rdsr/7w\nzRMOqCz6uTCOX5drR28jgu2mARdxwoXeLi8vK4nx7e1tPXnypOJx+iIY3XQA0480jcDo+SX+9gR7\nrGN3jzXiBf3I6cbH1edRzrPfCNP1xkTWmZvUGBGDQAyR2jv2UJPAIElDeVYuBhSNbbFY7qH2jOLV\n1ZVOTk50dnam0WiUam6J23icjXY5M/GT/COTwCgQJusmgOGhEpmPJ286nY76/b4Gg0FlqzUG5joC\nmGESrlvXtwMP27L9TFMH0Fz4gOt4mCMHuH6vmNB7rDhhWBcKWjXRfEFAj+PxOC3Q0f2N3pqHESJ5\niJ4Bri33Xtc+16m3bxXoflrAS9tg9WdnZ6rVamq323r27Jlms1kiL95ft+Vut6v9/f3KQVV+Ol6O\nfaJDSlqdCcfFD8zxc3495Ob9oU+RkROqyIUw6cc6efDT/yIY+kD6SoK77soBdM/OzvT69Wudnp7q\n4OAgrUrdbldHR0d3ThfzwDy1johnFqnl5dqvXr3SbDZLLrikygooKZW0OGv0UpS4+nnMj/+/bdDN\nTTZeEXT39vbSuRW+BdWZOQkBQNkBNDInJiyg67XRuTihj3duQnuoIcYp4yRytv4YcXfVX7k4coyP\nur7pH7YGeDjz8soXj6M76Eb25ZuMHIjWAWIkIK7D+0DXZdOgG9s4n891fn6u8XisTqeTtpe71+ih\nBOZgp9PR1dVVJVHsjzhyj8qPiPXDhtAjHgX9bzQalWvlEp+5vsS9ABF0kY2Bbm6C5RSMImikoz+A\n12q1Evs8ODhIr8PDQ+3v798JtKO8eGSedBt3o3xMUhqkyWSS6i/9ybQoDWBY5dq4C8T/YsLJEyWP\nlZxe75sU/N+N9fz8vLIgkrxxlusrv/fJJ7vXShP3ZCu1J9A8pJRztZhU0t2KhmhXOeB9rHC9uIjm\nJIY5YtIPj61Wq6WzAYhx+8Sl/+jXJ2ZcmFiI/L45QPX/uQ4jg/W/VyXUVrnQj5Vow84yWfAJM7h9\n8l2wgl2S0+k0MVz063blEu2OBY6ySo/Dsump3++nszU8vu6Ej7b5fVfluNyTW+dVSZ/gEHPvoCsK\n47m6urqTmIFNtdvtFBI4ODjQbDZL7j8Z4XjWgRuHl3XQSUAEkJnNZtrb29M777yjdrudwNyP5/OB\nzg2UxwBzA8rvfhDyJmUVy8kBlS9q6JiFRbplll6X6K6Y9y+CL6zO9e06cUDyrC3hB4+b5yZ+BDhn\nZA74jxW/Rq5aw3XrEvfYA8Lj8VjX19fJZtkFxY5K9J3zjgBufo+ge59+ctUJ0XNYtaDFvub6/BhZ\nZ5+rXP045vTBdYltMSbOaGMeAbtxL4lrca9Go6G9vb2EPb7rNFZpOemK4c74Ob83uLROHgy6DnoR\n6ZmkuKuu7Hq9XgFUWC+slISET1QXB0O/N2xDumU0e3t7WiwW6XjGXq+XwMhjwPQlB7jObHNxNh+Q\n+wLmn0TumwirPA3a4aDLBHcjiKAbY1FS9THpTHR+4hL6tefzeWJ4JN78ms4CooubAwQ33k0w3bjt\nFH3dBz4eX/Z4Idc7Pz9PRKHT6SQ7gNF5GEa6zayjC+wnp5NIcnIAuwqw4kKHeIjlbUlk4X5vaT3o\n+s4+tSoAACAASURBVMLBXPVrxh1h2LPnFaKnJCklhSPoHhwcVMheZN6OX9FjyWEUfavVaimEt04e\nBLpOo3MrqJfYYHheAuI1iVxzMBjo/Py8MgEcACMoxNWGk8XYoeYnSnmA3EvXWBz8sBKPQ0c30Y1Y\nup2wi8Ui1V4+VnIupXTXDfa/fdEjvDCfzyvlYz4mnL+A8Xrc1Q3MAdldtPi4FYARBozLSFscbLyP\nOYYTQwp+0tQmdEtM2/sawx+r2GW8Fq/RaKSTk5M7tZnYuj/mh5d0u6jVarcbMHyjhTM77hl/rnp5\nKAeJNuMlam/DS4t/M6a+mxSb4nhVn4eIs1PPCVH5FLe+0z+/Bvchxj6bzVLVCXgEHviCcZ+NRu9E\nUqrMolzuG9/4xlpdPTimu+pvqerKshI54GGQKPn6+jop0cGAie5MM8dEJen09DQdioHCvL7UARTQ\ndtD1ZEeMy+V2CuX0sgnJTSwkJnlcPNSxu7urWq1WeeIsZyx4opFSHphAvD4G5rF4r0lFvDSMZESt\nVkvg75MoMl2fTP5yNsPuw03o1qsposcU2WYO3OL15vPlwfknJydp8W02m+mcZzba4GWRLWcs/EQ4\nB91VIYnYnpw+77MZv+7bAl1vL/cGdLE/jmV1jwnvgTZFskNY5+zsTK9evUqHMpHQBEyxVzxoxqHb\n7SYmKukO6PpJcdEziR5PjNnSThaW8/PztGt2nTzoGWnOOnNuRHRnodc+wLBHFOANpVCZ+GTcEpyr\naIApO5VHmZHhOuPhXt52B3s3yGhE635/U8kxFG9b7j0HNQeVGH92gHM26VUXbuQOuvwPt8knqRux\nG2d0F914c25xjNP5UwM2AbroK06g6D5GbyPG+/FquJZvA+12u7q4uKgces6jYoj7EtpyV5troQOv\nClrVh3WJM5cc8Hq4722BbhRAjWec8TgdHhLAeNBWXxi87cxfj/f7oexUHdAvr3wgfMA8iXkP3vdk\nG8n2WCURN0g46LLV+PXr13r16tVavTwYdNeJGxA3x3jjyg0o8vQHMuPX19cJdP1Jos563Wh5hpUf\ncOxPhmDVBGzn83k6t8GBOh7/54tLrt+RxT1WonGt+z0C2GKxqIDV6emphsNhcr28ysLLyABE6e6T\nJubzeXYRirrw0AwMw8+AIMQUd6lFAIx742EK/hy9x+jWQ1WR2TD5XBcxmcoEazQaKXELCDDxJaXS\nx8PDw7ShBDuMwOg7rBjD2FZfjB10c68c6EbgWheTfFtCvzmr+cWLF2q1Wml3o7NGcMYrPyBqvV5P\ni8UinXl9eHiYznYAdONRnR4u9LGO5I/xi+EmB/dY/RNjwA7YtGGdPAh0cxLdABrKBGJCumGjVBJp\n0tJYo/LYlss5pz4Y3Kff76dHNOM250q8vGQF0PWzUVFkzkX7JAz0TcXjV/H6DrZMdI8tebwLJgHo\nYmi4v9TZerLT2VxkRauSm0yI6IUAIp5UcAbsfXGm6zFnDzltAnRj/NaBikXJM9Tet7j4+nU8LMCC\nvb29fLLJwcFBpdg+LqruNXBPwDxHMGJIwdvv/8uBbJRPC3ijV8zOvo8//lh7e3s6Pj5Wv9+vxEc9\nrOULOmOxvb18jJYfOuMPL/CaWw9nxvgrunXP1+twI+iCLTF553MUjGw0bk+wWyf3gi7MwBvujY+M\nDHdie3s7ZXJzE9yLy+Nxgs6cnQHECetutbOUWKZCnJAB435u/NHQPy159erVndKXVRnZWI1AvIzj\nHc/OzlK8yw0WXcOwViUAc66qpMqY+cIW67Fxj2EDPvEQz0bHQ+qpSKGg/bHiIQR+Ykf8TZvjphi+\n7wXzbpfSMmY5Go10enqasuLD4bACutFddXBZldRz79Lfc08nhhtysWAXZ/OrNgJ8UlllLzHcNZvN\ndHFxoY8//lhPnjzRcDhMOYfoOaIbPI1arZa8Xp8DPmfokxMBJynOTPnpmyr8fcYCHCPc5Uc6Rkys\n1W7zGXhA6+TBoBsV7K64dGvgFJG7onzlw0BYydzlBLRRFCEHlO9GF+Ms0+k0gXiubCo+R8lPnoog\ngnwartiHH35YOafTd43Rfj+gw1/ull9cXCRdbm1taW9vT3t7exUjdn07qK+LxXqGPhdzj2PrLqPb\nCkJMlAWD+C2AS2hkk6GbCExxAgIMjUYjJWb4rOcFXCfEuweDgV68eJHiiGzE8QNXqF/n3n4WSNSl\nzzP/3ccqJnQii3MAiXqANd63a+o+uW98HEAddN955530KHWPPfO7V4NEEsaCFwlKDAViv3zfQ1wx\nl+DkzfXFfMMuHXSj9+bzA7teJ/eCLiUVEXi9JIyGStXysXgOgB9a466Eszk6BdjEeKODRYxvxh1B\nkR1Gl8TdZD9w59OUX/7lX75zSDtsz+OdOUZIgoIXIZm9vT3N57elc0w0xI0X/fvLQYjvYVT+bCpf\npHwMV8Uaubf3jX7RH9+U8VjJVSfEWCniE9XdTU/eut04g5tOp2n3U9y26idlRW/MgRddRlZGOz3E\nFEHX+xDnagQjz6m8TeFe5BBGo5Fms5lOT081GAw0Go3SAu4YAmtFJ7GEzvuf++mLv3uz6BJs8XCB\nt5nPOst123Sg55rUqTcajfSA3HXy4JhuTOLELbO+Jz+6xh4ikKorSi5x4YkWV5gbJL/nBipnvD7B\nGo1GCsg/ffpUvV7vzlbfT0u+9KUvJSbrr1xIwf8f3yeeTv/Oz88TAMT4ok/KuIjF6oUIUNGofWz5\nPVeG49+LHkh8gKmHiN6GeGzTXWG3FRiv98kTJoDJdHr7ROqTk5MU13WCEfXjFT0xHBaBJY5V1Ouq\nGK2zeIAWsGVjwNvSK/1xQJWUSkVfvnyZnkKyt7dX8Zi8PzlX3sM03s9YxcM4cT3mhz9UNHoNLKSM\nKWSG7zgrdjwhhzIcDvXixQt98MEHa/X0INB1tyo36B6E9k6gtBjDinEzjzV6mMLjMTm2LamSLHIj\njm4zimLB6Pf7ev78uY6PjxPoIpEhvE350pe+lIzIgTau4L4QOZv0/6F/SQlw5/NlpYcDCH2MIYYI\nupIqY71qHOIi6u2ICx9MwxcNN2gWcGfmbyrrYvQ54PUJ7J9xe/J+ekJmMBjo9evXqQ601+vduYa/\nYnWIjwcsLMZto+379bxfsb/YvJezdbvdjeqW+8ZFhsWJkOBgMNDLly/TQz+pqY/fc0/Vx8fjsP5Z\n7N89FAdwvG8YrLNVT9JjkxF0vUwwesSAORUajwZdOusrSTQ+76AnUACJGCtzhUmqsFMPfnPvaGw+\nYfy8zRiXjUZLadPu7m5iuZT4uOI/Tfna176WZZ05ph5ZvutHun2ETq1WS7WjHtP1xCETHX3GhQ9g\niMfr8YDG+OK6TC70H11AGIdXnWDQTABPsj5WIhPMLagRqFynkQGjq62trQS45DEGg4FOT0+1v79f\ncW+dDHh8PZIEjzeikzj+3icfQ+7ndhETqf5cuE1uYV+nd2wC0Ds/P9eLFy/SnO33+4kR++LD50mq\n5oA4Xn8+n98JV0hVwPWHszqO8H3PlRD28jyTV7nwwobPzs50dnamk5OTtbp50ON6nDE6I4mxmBg+\nwIhicXnOeDzuWK/XU+UD93Og9vt5uUhk0t7uxWKRitX39vYSy+33+9rZ2fnUwRbxuFx0z+JE8s+u\nWiDc5T07O0sTjue+ORBwndgGd4EB3FwZlI8D9+VavoDGInM3bEIjuVDRYyUXJom6ixM0F1LJ6Qab\n9glPWSKLjtePeg4ht90c/eXOyXCvwYlObJv3wUkJu7M83PRYT26V/UVywCJMKOn09DTpmJpdwHZr\nayvlclwXcQGMnpjngtzboj0kxGCthAOizmazWWLCXukUSQ4EEiLDd6jKICy6Su4FXYDPwcuZbpyk\ngKgrxF19vu/siJ+5mFcE3Vhq45lgV0ouDtZut3V0dKTj42O98847evLkSYXlfickDn50XVYZtgtG\nTD/Z7Scp1URPp9PKjj1P6DgYx5c/HdnvFRlYzjtZFb+NFRjuzntyaROSY7ro3cMiqz4X7d3Zqntz\ns9ksLSQkA73uPAe60SsDaGJ2PoKuhyQQDwv5mFKpQGih1Wq91dCZM1WvNIK1snX/+vpa+/v7evbs\nWTr0ivNyqbn3g4/iGLkHgscBGEbGDOgyNhQHOEnDhkmcuRcWF2T0DuFbLBabBd2oUP/dG+DuV/zM\nQ8SVGmNgnhCIGWB/xftFxuIsyt277xZxlpWbGJGVIbkYXmT5MTyTA1uPMXpVh4cmpLuPaYoLR2xX\nbE+ubf7d3LXehuRCDd4G70Pu/7n+utfgn1v1it9f9fK25OZd7vvcP4YA37ZuV7UpMl+AclXeZhV+\n5DBmlb4i8Vp1r3W2mbtnbMuqufYm8mckLcpr7evPvKFupaLfottfmfotun17ui1SpEiRIkWKFClS\npEiRIkWKFClSpEiRIkWKFClSpEiRIkWKFClSpEiRIkWKFClSpEiRIkWKFClSpEiRIkWKFClSpEiR\nIkWKFClSpEiRIkWKFClSpEiRIkWKFClSpEiRIkWKFClSpEiRIkWKFClSpEiRIkWKFClSpEiRIkWK\nFClSpEiRIkWKFClSpEiRIkWKFClSpEiRIkWKFClSpEiRIkWKFClSpEiRIkWKFClSpEiRIkWKFClS\npEiRIkWKFClSpEiRIkWKFClSpEiRIkWKFClSpEiRIkWKFClSpEiRIkWKFClSpEiRIkWKFClSpEiR\nIkWKFClSpEiRIkWKFClSpEiRIkWKFClSpEiRIkWKFClSpEiRIkWKFClSpEiRIkWKFClSpMhfL3J8\nfLyQVF5rXt/3fd+3eFP9Hh0dfcfb/938ajabb6zb58+ff8fb/yvk9Ynle7/3e7/Tbf6uf3U6nZW6\nrd2j38WP/MiPqNPpqNvtqtPpVF7dblftdlvb29tqNpuVV61WU71eV71e19bWlhqNhur1+vKmtdvb\n1mo1NRoNNRqN9Lmtra3K5/wnr8ViUXnN5/Nlg+3vxWKh2WxWec3nc02nU11dXeny8rLyGgwGuri4\n0GAwSK/Ly0tdXV3p6uoq3bvVauno6EhHR0f6Hb/jdzxEjyv1+0M/9EPa3d3V7u6utre3k85oy9nZ\nmV69eqXXr19rOp1Kkur1utrtttrttg4ODvT06VM9ffpUOzs72tnZ0fb2dmprvV6v6E1S0sH19bUu\nLy81mUx0dXWl6XSq2Wym6XSa/s/f19fXmkwmFX1dX19rPp8nXfOq1+tqNBppPPgM+qdNPl787nbx\nwQcfPEq3P/zDP6xvfOMb+sY3vqHhcKidnR01m0298847ev78uZ4+fZpsudFopLZsb29XbHpnZyfZ\nZqPR0O7urlqtltrtdpoHzWYzfY/+u+7pk6T0v/iZ3Cvqyn8yLldXV/rKV76ir371q/rqV7+qr33t\na/rqV7+qjz/+WCcnJzo7O6uMD3J9ff2m+l38+I//eKWN6Oajjz7SN7/5TX3wwQf6+OOP9fHHH6tW\nq2lvb097e3t6/vy5PvOZz6jb7er09FRnZ2e6urq6M1+vrq7SHBiPx8n2sE2f7/7T9Y3tbW1tpbHh\nd8bVf25vb6d+MA/RP9jFNdH7ZDLRxcWFhsOhLi8v02d+6qd+aqVut+7TrgMmyt3a2rrzvhtHGhkb\n5NwkcyXVajXN5/M0WSNQ5N5z8I2GyUT3e+bA2dvSaDTSgDBAAAVANZ1OVa/XE/A8Vhhk1yW6YGHA\nyLytzWZTnU5H/X5f+/v7Ojg4ULvd1u7urnZ2dirXjYvaYrFIE3Y8Hms0Gmkymej6+joBsQMriw7G\nz+vy8jKBaRwjjNQBHIm24osk47MJOT8/13g8rixW29vb2tnZUbvdVqvVUqPRSGNMWyAKtGc6nVYW\nD+yC13Q6TTqez+cVu8yJAwW26++5DmlPvBbvAxRHR0dpvAaDgV68eJHAgHb5OD1Wut1uZT5iv5CB\nTqejwWCQ5lGv19PR0ZGOj4/17Nkz9Xq9BHboj3mFrUEiRqNRhRwwJ3xOM4a5hYzrsHgCwP7i/dx8\nQQBb7Ela2jtzZLFY3PlOTu4F3UajkUDAJ35uJUYcBL1x/C+CLhPU31sHuvzu9/G/3XDdeJkQ3s54\nbV9Ytre3K6ALIF1fX6ter2/EiB1ovW3cj0EGFGhfs9lUu92ueCCtViuBbjQmNzZJidWOx+MEpldX\nVxXQBWwx9NFolD7PdwCd3JguFovUfoB6Fag6qMWxeVO5uLhIbazVatra2qqwGjwqxpF7AsSz2SyN\nDSzMSQbg3Gw2K2PoAMrnXDd+rxzTd1aV04V/h/t2u109efJEo9FI3/rWt9Tv93V2dqZms5lAIC7c\nj5FWq3UHA+r1evLaADl+Pzw81LNnz/TkyRPt7++r2+2m9gOWjUYjLRRuO7VaLZGhyWSira2tCui6\nF5tjqrTDx91fPldyXrffx8eS6zebzbQQR9zLyb2gC+DCVpisTA53WeOg5tyjyGY85LDq5dfjZwRY\nJBqVG8YqRp7rM6zXQQBGeHV1pYuLC7148eI+9d0rq9xIwAzXK7Zrd3c3sTUG3a/BNd143P2lb4BG\nq9WqjLEzVAfd4XB4B6gJTTD+kenOZjOdn58nt5E++ssnzjqW+Enk4uIisXH6TBgHu86FqqKd8Fl+\np71M8mazmfrkTNi9wpw9R1BFd7R3HVGIOmo2m+r3+zo8PNT+/r729/f1+vXr5PXE6zxWdnZ2snPV\nF3hstNvt6vj4WO+++6729/fV6XTUbDbV6/W0tbVVwYPr62uNRqOKvlkcfWFztumLdQzbAIoQEZ8P\nHmpYFV5w+3Cgh3TRPsaLubBOHgS6rDo55oVEw0UBq1xJvz4SWd8qwPV2rTKkyHTje+tYNG2JoLtY\nLHR5eZniUJsIL6zS0Ww2S/qGiTkLx0Vut9uVmGNk7G5g7kJxv52dnQS4vqACfs5Uh8NhirE58I7H\n4wpYO7tz1288HicWE1/+uU0xMkB3NpulCecx71w7mFDRfgBDD83M5/MELlyPfsxms0puIrqckeFG\ndhx14/YZ59lisUiM9vDwUAcHB9rb21O329XOzs6debUJ3QK60Ut1lx0b3dvb0/Hxsd577707bn67\n3a6E70ajUUXXHrpg8arX6wnYYn8cNBFA1UOiPh+cCfP96LHkFkI+52E7wiDr5F7QddTGmDzO12w2\ntVgskw8x9BAlgiDv+c91cbBVIQX/TGRLD5nAfM9ZWi5e7azQE36PkRha8KQTICjpDsPtdDoJcGGv\n67yFOB7oxO/lusLA/Nq0A6AmDOGMl9hWBFJfGJzVegIlx5QfI5EcOKvGi3AgckbjOQxP/vk4uSfg\nCx4CI8t5V7jV0YZzNp1jxPF9QKDZbKrb7SbgbbVaiTyg400A73g8rvSJsTs7O9PZ2ZkGg4Fms5ma\nzWYl5OXkICanogfNGERPz3Ud9Zr7v5MOB93IaLlH9IyxU/8ubSXBDAHx3MUquRc1uAirj7udl5eX\nKUa4LgHG+9ItyGA06wCB7+X+jsDLwDF46wzU28l7ccJHwGXwWq2WFouFdnd3NxbTjW3xCoIYj2y3\n2+r1egl03V3OtTvqNbqZuPzX19d39Bzbh/u4u7ubWLhXgRC3ddYLwLr75kmzGFbwifVY8Uns/Qdw\nr66u7iQvYZqA5XQ6rSw8kcEzF5yFuW26GxrFxz3OA58f/jv/888heGedTkeHh4fa29tTu91OIEGf\n1nmID5XRaJTu7UnF169f6/Xr1zo7O6vYC2PvevQFADtk7uY8Xn530M7pO87bXFI5MuKcl55LpjMP\nffzx4MbjcbKpdfIg0HXj8XIrJhINRKKSolK8gzlDc8m5Xg68kVUx2XOAkwuB8L/cChuBC6abu8ab\nik9UXzhycapWq6Vut6ter6dut6tWq5UYZATc2H5nea53QMNXaG+TG650y7jRN9+dTCYajUZqNpuV\nygfGw0GX2Fhk837vTXgR9NVfDpQwVADTgZ+2kEz1UE10/eljrBJgzkTQjYus99vfy9mpv5+bF1tb\nWxXQJX7qSaDHAq4kDQaDO17Z9fW1Tk5OdH5+rtFoVEnsxkUpYoN7Wx4aw21nLnAd9Bs9jHiPOB9y\noBuZsdugEwVfwN3+6Sfhifv0e69lk/iInYzB6OjG5wAApUTQzYGnG6F060K5AftEiuwwxmYig/TP\nejviKukKduaUY5JvIrlVkUlEvAnjAHD7/X4lgebGE90o74Nng5EYVohhnJwX4bqnDzCA6FEg7uIR\ngvDFxSeCVxY8RiJoeR9YLBz0IhGA6TLmMWlGf5BIIOICGklH7jux3YDQQ6XRaKjdbqdkGl4R474J\noiBJH330UaVvzA/CCh4vhRSsC/W5N8n3PIbu3qjrMgdycT4jHsuNIYdceaWHGaMtgUP8jF7zOnkw\n6DogSaoA7u7u7p3kWG6lcaXkGC3KjKtybiLnmIYn+dig4QwGkI3uby6sEIHd44+LxWJjMd11bqUn\nfra3t9Xr9dIrJtBi0sxX8lz7o97jGNC2GH+NSR1nBeuYWMzkewzP++uvx8p99gL4S8pOLA+PSErj\ngThL9vGMuvWJ6QkZ16G3l+95KCMHLLGPtKnVaung4ED7+/vq9/tqt9spBrvqe59UAN24uFBD65UB\nXi3iHqWLe1TEgaN35n135sr3o53nQpm5Gl1nx05gInFx/bEQOLb5eK+TByXSvBFxd1d0yVxWuRI0\n0Ff7VZ/xny6egPGJ4Qr0+6xqd+47rkBfxd0FAiQeK7HP3NtZFSUv3W431eX6RoiYpMglCKJO/d4O\nzHwm531E0PXPINGVIw6WY958PgLuJ2F2n0TH0SvyutvIiLH7nIcTvTyv/XTde59ztp8D3nXjFSUX\neqjVamnjDDtG2+22BoNBxYN5rJd2cXFR6Qcv95xyix5tzC3cniwG0LykLOoikjlJdzDJF3ipShZ9\n92x8xTmUWxidwMVQyzp5EOgCtm54udhhVKQrNAdqEfRWMc1VhhhXTmefXMfBOZch9YQNAxPjw749\nFpeUVfOx4hMzMkNCCxSc+0YIJhNJCgfdVTFpd7fimDFhKIWiHTCuVWyYNvvC5Owxgg/f4TP8z9vP\neG1CYh+9nYCu2wCTVLplujFMQELTS4xirWeu76tCUrlJ7wD5EOD1zzpbxE7Ivfg9HyM5YPEF1cM4\nHqLJ9RNduSdRr9crjNevnfOU1+nF7dLv5Yt8XIgioPs4sChfXl5qPB5X8hfkCtbJg0HX3cccQOZW\nnahY75gzzUjtna6vU2oE7uhS59hqdD/8HiST4irm7MgTTm+jZAwBdClRa7Vad87A8BBDDnDXTXKP\nh6EHjGUVq0U3kXlEMHOWEdsSx813zPkOsU2CrrvpsaoCNstn6Q99iIALc+fsBb7nrDe6pqs8qcj8\n1nkmq7zJHJvEdjgjgvh/bM9jhBhxjnBhD56kjeFHFnJnlmAM+nSGyrXjIrjK08qFkxxznPFGzPHQ\nRCSS3JfqLbYoe+jy0aB7fX2dmO5isUwe+IEfTHwPaEeluLJd6RF0c6s8iojXiDHfqKj4PZdodCid\ncg8fLN8Gy6tWq93Zg/2mEicihurghdvliTNpaYCxGJu+Adh8J67o0Y2SVAFajD1Xf8pkWMU4fLHz\nBS8mpZxxYNB89z4m8xBZx4jiguwLhQNTzoY9xIDteIwwFwt05hvvEz/j91rXr/t05PdcFep4U4nt\np13Rm4yLaq4dUT8Opg50zI9YZujtWedRue49YetkxUMT0Yt3whHHAfzZ2dlRp9NZq7sHgS61aijR\nAdfZVlwtYuwq0vfcAPpAcC2XHLP19yODyH0PYHXwdVdQulv8HkGX2tbHSmT/vvUX1kKpWnTBvX2w\nCb7jLIcwhCd+ckDgBud6dDCo1WqVbHLUues7Aq6XT8FqvT+rFus3lVWuqNvlKtCl37nYv4Nu3O3n\nJ7zl3NUIxvG6q7yT2Pb4XhQf400Drrc5zlMf8+gB5EA3LnIOvHgh7kl5Epzxc/KQI12ugzh+/tMJ\nl+vQ56ePQVz8AF3OlVglDwJd6vwkVZjuqvq0OIEAE5/McWVyMMytVhFIc8brMd51hsggRQOMbD2C\nLuAG8GyC6SIOAO6eONtFPxggbg0nfrH61+v1ND7dbjcZqk8ATyB4mMENnp+uY9fPKiaY61OsyWWx\npF+ejHgIi3uoTnOTI7ZNqm7H9lCIx/Z9JyYbg3yCxkUs6i3HDGmH6zl+jrbwHek2/7Cuz67LTejT\nJYKchzZ8jkZQc8borDgXJom693CFg65X76AvF/fycolmt33wJ16HzxGSigsF36fUbZ08KKbrpVXR\nlfIAfRxYgAsDAVAoSqehMQPsbhvXYUXzgfPfc/d3iQATjTGCvScCvNifGmAPfzxGvP0O9P5/DBNg\nHY1Gd+LMboT1el0XFxfa3t5OTJe4HjFiKiEIQ+DNxNi3645wQC4EEN2sCFy5RBs2Ed22Tco6b8v7\n4YuAL3Kz2fIktsVikY7CHI/HGgwGKZlGdQkJz3g+sifqXFw//B0nswMYbUZ8jFxizNHPoNiU3e7u\n7t5h57wgWLlQCja+WCwSFnioKh4v6qff8dnclnXANBK0Wm2Z8GaDTi7/gV06OK/yOrgHSb7r6+tE\nPCGnGykZ8wt5ptZPt1rFJHzFYtfSaDSqZH39OLh4OAUD5eU9udBEFAczfy/nEvmKmQNdmA2gm1sJ\nHyuuJ2e6DrqcMwrLjeeKutDPCAg7Ozvq9Xo6PDxMIYr5fJ522kUX35maG7bH7dBXDjRcl7H8yhlZ\nTh+b0mt0AZ1tuQ042DoDhyxMJhM1m01dXFxUvDyO2eRMDGqpOffgIRK9sNz70aZpM7rnPScLbFGd\nTCZprHNe3ieVVWc2Y6cs/pEtOsP1M5n5f+4oUT/bI4aDGNNV4YF6vZ7AcD6fV3YYRtAlSeohIg9f\nuv6ZV9PptHJc6EZAN64mHhiPAMiAuyHE1Yv9ySgEY47sGffYt116TNIV6+30gLufEREzirkY8ZMI\n7QAAIABJREFUV3TL3EAoFYvlOJsQd3VpM+2DtdD+6Oq6cUfQQ/8whKurq7TqI51OR1dXV+mkLA9h\nRO8i6inHKnK6ZKK3Wi31+/30WX9yRQT7TYAuO+R8EsTrOug620JHrge3f39ShB9ExKlavjGh0+lU\naqodQAF1Z2Au6NS3pHq7HXicObNAczIcTDengzeR58+fZ0F3a2srgbtXo3hSmjM6hsOhhsNhZXz8\n4CRPKue8JCQHoO7ZeIgjRwziyWjRa4kEAn0D5owx/X509cKqEIAnnaRqKRF/854rEeDif9PpNJ2f\n6bGV/f39dEqSKycCSmRnHheNj+Px68fsM/HJOOndPYY5tlot9Xo97e3t3ae+B4m32/fxwxzwEmC9\nHrvNGX5kHrkde9x3PB6ncxwAEh/DGKuPsbaoqzgm/M15ryQFm82mxuOxXr16pZOTk7QwrKuK+KTS\n6XTSokP7/GcU2u2H+XhtdnQ9Y4iMyXpwcKCDgwMdHh6mF4+r6fV66Rpupz6x/UhPxtrBm/nnYCHd\nxsm9hpTHT7GwrfIMP6l8/vOfr+jBdYFXSNmXE66zszOdnp6mF8ekon8IEqC9rhTSCSHveXmYj6mT\nJ8J3jiswV8JxPJFlf3+/UpXioSrqijudThovzgNeJw8C3Zih9VUDcYboTAkD4OxZXw1xk4mTedz4\n8vIyXcf34jtgc98YM/TYmz9exjPOXoKF0eay585C6Tcx0U2AruvLwQzdw4ZYNGgfBhOzw/En+nWD\nw6jdC/AnTzgjkKo7uhzE/RyHHOB6bHh7e1v9fr9SZ3x2dqb5fK7hcJgAfBWbeRNpt9uVMkDauW4c\nFotFYmHUYOICR2/KXVxnwYeHhzo6OtLTp0/1/PlzPX/+XM+ePUuf4wXhiCd28Z4X3QMA/X4/ubMw\na18M3F5gug66m5L3338/uwBNp1Odn5/r4uIi6clB9+TkRB999JG+/e1v6+XLl3r58mXSL3kLPGHO\nGnEvwd1/xsBBl/ivJ+gIY6APciK02UNw1MI/efIkeZwUDoATzAdIG5VDjOd9i9qDnpEWwXaVOyvd\nBV8aR2P5PokbZ5seMsANBnxhXT6RYX7uhvA7husvd8nol1dijEajxGp8gnkZFwuGJwgfKzlX3UMs\ntFGqFoe7CxUZgC9ikiqHWfM5j1l7+YykymdoI/2OCQ53HeMLg/eQDEm87e1tDQYDvX79Oi2UmwQG\nzxHkqmeipwbr5HhKz2PESc53+OmhoOFwWMlFEHsnu+3jSb8Bm8vLy+R2+yOTeEgjoOvnKvOsvF6v\nl67pz7HzzQkxHPem0m63K7bHvObpFf7Ip2azqfl8nh7iyJm7w+Gw8swzJ2iedGMeuDcWY630Kya9\n8RJdH2AKmAYuYcej0UhnZ2cp/OleRs7j9+Q0Y7lOHgy6fhMHXuk2BOGMDQHgoovgrhzfd/cHcJtM\nJkmxntRzhohhOgBguDxz6eLiorLNlX5gsP1+Pxs38piqr9xvE3QlpVP1O51OmmTRtYcRO+iiW5KW\n1FU76KJPT7g4U5Nu42TowMNEbsT+YEteHs7gdXR0pIODAx0dHSWAaDQaevXqldrtdnLJIjg8Rvy5\nWA6MrjMEu/GyMOwRN9kXe9qXi/8Ph8NKBv7i4kK1Wi3ZGt4S9yUMEF/+IEbsuN/vp1gjrKzb7Wqx\nWKTQgwONMz/6vQnd+m48QKvRaKjf7+vo6EjT6TTNQScCgO7p6alGo9Gd5/A5KPpY0AdnvFGwe8A1\nZ68evpvNZqnclbnvXs319bUuLi4S48YbpBrIn4SObQH46+SNQDcyXQddDy04OMaV1T/jYQWuSQc8\nieFHSHqMxk9tZ/LEPdGsmnEnWSy1wkWKoRI/BjCC3mPFJ61UZbqehIFtYozoyldedOTJTBI9npzz\nyefjE0uAGCf0DMC6uwZAeEVFjCMzSeNGGqnqrtO2TYh7aJ5w9KRw9GriRhPGw9vL9113Ht7y/nPN\ng4ODShgFhsUieHl5qcFgoJOTkwRW/oRm9zw6nc6d5ODe3l5i8zHzH4+w3IRwGFP0tIjZ+9GMzG8H\nP3+kuidUHXR9XjDfO53OHaCPeADhgBQ46/bELu3zRFvMgfj3J5OJut1u0r0fvVqr1RLbvQ8XHvQ0\nYI+Feh2tVC21cUV5g6ML6o/2lpRcBwd0BpFsL66ZVN0phJIvLi4qLgUxG1an/f399H6saJjP57q4\nuKjEm5l4PuD01/v0WIkLFcwKd5wzFlqtVgUU/KkdvuGByUDoJDLdGJ/2TC3MGhYBOyHGORgM0mPN\nfeJ4OZJUrcdGz7A34n2NRkMff/yxPvroI7169Sp5IpsCBQQgYHKxeAMMvvhHEiHdPbUqJio9a+7n\nDDCWLJSAPgsgwBkfBU9CkXFl/HzR3N3d1f7+ftoNyrkKEJXhcKjT09MUy2VDzyZ1G6/HvBsOhzo5\nOdHJyYkajUZ6woozTWzcQzDgQ0yCMcfxHvAS8ATb7XZlTsMyYfssdFzXySDj40lM97r5nSS2E0iw\nCY9Fuj1W89ElYzHb78YWP4Oi6BhF5CicTKo/3LDRaOj4+FjHx8cJGDwkgStAXIj7Sbfx1gi6vnp5\nhtcXhMFgoMFgkErYxuNx+hzXjastv7vLswlxQ5Bua6FjDBT35/LyMi1+0i2jYwJi7J1OJyUKmJQw\nZIAHwMVd6nQ6CQAw1MlkovPzc52cnOj169cVtssC5WPmjAO24aALEL98+VIffvihXr58udFwjUsO\ndJ2NsXg6w4+xXvcCPB/g9hXDXNgG9sYkJv7HAxkBDti4g+4qogOJ8Moej4ESk8S+6R/zdhOJSvd0\nHTgB/NevX6cn/3q4A9CFHcaqglhd47H28Xis3d1d7e3taXt7+Viig4ODCsD649t5z2PvMSfiCTXG\nGB3FEtWYGGbh9JAopZfr5F7QZd++b4TIDYBXM7CiO7PwDhPEholRYoNrDxPzh9p5XSRJONwtVne+\nG93CGFOGfdC22ex2a58nAiPT9TioT6zHSAR1ADcmS3q9XgXwYZjedl/4GAcPEdTr9bQye5KJOBkv\nmBtj7YyV9/kcTwKWbh/l4x4Fuh6NRjo9PdXW1lbSnT8ifVUY6jHiDNVL1XxjgwMHn3f3kvHxcUE8\nEevf8wx5HEufT16ZE+Pnrg930Un0DAYD1ev1ytGN/N+Zrh/UvmlhfsFkue//3965Lbd1JFk7AZLD\ngwCKZ0k+yr7tftd+pXmBvnaEO9ot25JM8wCAAEFSlAjMBeMrfDtVPFgEZ/4/ghWBoEQCG3tnZa1a\nuTKrajAYxHA4jE6n09j+Elt6nHqMelEC18+RSEQ0Dt/c29srUfXKykqxz9nZWSOhmROonoRqPhAR\njcksIhrypvMrxhWw77Z2J+gSnt8Eug7HeIjJZFKc8erqqpws0el0GqtQAF9qGHGY8/PzxmYtLmcC\nfGFXDqlcdpRnTgZAfgEUPEvuJAMvv7P4/9DmgeWwy1UVZKhJJpJ8cZYdJ+bZs6YeMQt/PJnRb3mF\noR0SKYhJwRFBv98vMgvAhvNNJpNSRXF+fh6DwaABAFwTJuoJcx5AYdaElIItef6sYS8sLJRJhvuY\nTK5X7HE2ndkx17Mc0e/3I+K6igC/JVrpdDolC+7Q1veALWjON0REDAaDcm/oiMhKhOJUBzyGtECz\n7j8ej6PX6xVpAbnI+QZXeIABgBT95CQ1Exn+DdawyGZrayv29vbKeFhbWyt6NqCbk6A5Ysf3IY0A\nqXX+iCgYwQRh8pYj/bvavUHXCZDMSHBWr6j58OFDYwNiPxAsM4db4/G4XN873/uAu1wyQifC+nBY\nQg3A6cOHDw0QB+gdQuTnykyXf5ttPrRlhocjuLSIe8Y2TGQ5SeCJxjIPdsmnTqysrJT7wPnoQ/ot\nYpY4jGjuMsckMB6PS8jlCYwCeSIYahgtQ/B/a+bzalmyQXLBn81I8GEWbXAv2BDAfv78efGnVqtV\nTmdm4EZEIQLZ53jdtITWE50jrhwCD4fDUkr18uXL4hsRs3IxJDzr5I+h6Xpy9YKH0WgUnz59Kv3v\n8iwnjZlwI2Yypf3YWiyARz9sbW3Fzs5OXF1d1zYvLy+X3AMvEtC8IA0uDABPLNHY/xknliyxd46s\n/bmb2p2gu7Gx0TgSJmK2sbkzgGZqzEbMAg7XmdUcEjNAI6IkFXIoBiBkQbvVapUBwfVgJnbiyWRS\n7o3E2eXlZXk2mAKGRMt0zR+dD5uAcTyk5XDKk1Heh4Lnj5iF8q7vvKmUje/IE5ftmZ0vDwTsyedx\nRMqg0IoZAEgHAM3m5mbs7OyU9378+DEGg0HR7QEq+mlhYaGA35c2lr5iO7NFJ0ddq+l/Yw9sAGPH\nllSYwJjxcYeYtnWOEulnbLi5uVkqQpBhIq7Bv7Y/iWU/3rewcL2a87vvviuM9+joqBG5zZv1OmS3\nnkq1C5POixcvCruHZFGl4VwFJYwQBiKotbW1eP36dXzzzText7dXyg6JlohGdnd3SxS9urpa5B7K\nT8EN963lRyexnz17FhsbG7G5uVmWdZNn8ebw1sofXL2wubnZ0GZhNzho1kCYCZyxZebyjOCOhz1G\nRKNMiocyE/BMiQOh8WD4iNmSSCfPHEJcXl7GyclJAYTV1dVyX4TnudA6gy5h5EOa7eBSJicADbpm\nDmR8c6mWdd7baqzzdztSyRl79M+IWbUEEYn31EDqwTZ7e3uxt7cXX331VXz99dexublZ2NCff/5Z\nQNpLQe+ji92nEYlkXT9ilm33oMu6Os+M3wK6kAEX7DsUxic9SWXQzYQB0AV4Wq1WmTQoleJAUu7Z\nESjva7fbsbGxEd9++22cnJzE/v5+SRh6DNZyMw9p+EkGXbRWgAocWVtbi16vF71er0Sk2AgQZ+ya\n2X7//fcFdCFoBl3q7YnI1tfX4+TkpFTNeIWhCYzHxsLCQnQ6nbIVAYd8IuOQj2IS5PnN4G9rd4Iu\ny0JxXIvbZrk2PAawWO5BTIdn/crOTnYdoLTuFRGNGQu2QAbfBvBnMSgDxNqcw5CI2fp1r+ixgA64\nzLM54eP13o4KvMwXRs97LS3wrLl6w7Zzy1qVQyUDkxOmnvTyYg1+v7OzEz/88EN8++238c0338TG\nxkYcHR3F4eFhXF1dxXA4bJRQXV1dlV26jo+PH2RP7rXVapWQ0AkQR2ZmwZAJWAxsHJstLi4W+Sdn\nt2Gn9J1ZrnMEnlwApG63W/YhATjoK5YBdzqd4g+UjfE+SM7Kykqsr6/Hs2fPGslC+v4xmC5+SyRJ\novfs7Kyx9BufsV2Wl5eLDru8vNwoc4u4jrZ3dnZid3c3vv7669jd3Y3nz583ABrswD6Uc3U6nVhf\nXy8TPVovvsokm8cLk+Dm5maRIj3h8T4TGLDxrgntXod8mTEZMN15WeMFGOyIGNyDmQ7ICS4DrNkG\n/+d6EVFA1+Hh2tpaTKfTxgY1Lm3heaxzGmS91NVs3t89r5IxGsCHlJMnGk9qtCw5uPg+Jw0cUmf9\nycDj2To/d8RsQxayxjAoHH99fb2U1Hz//ffx448/xsuXL2N3dzc6nU6x52g0KsDAirXV1dXY29uL\nFy9exD//+c8H2ZNlsR5YtVpg2y9PzkwIlm5gr9iQCQfZhO+z/QF7b/wE6Lpsb3V1tVwHUF9cXCyg\n2+12C2Cx6ZLBmQkgr9I0AXG/PrTxHJyYAOmBtCAfUGfM+zyBPXv2rLH0GSYKsG1sbDT2s2ApdJY1\n6ctcMeKENFKDK1NMKiAx7K3C5JXPmbMMZ30bNeC2dq+tHQGDm6oX/CWeeQBdnM5GyiUWNhQs2SVm\n+fusT1mf5P5gviQ6vKrk4uKiCrqUvpCtz2vwI2ZhmSeThzSDWgZdMzUzds+wvjcGP3qWgZu/Yze+\nM/cZ8oLvLbePHz+WFU9eEIAeBiBsbm7G69ev48cff4zt7e14/vx5CcUjrrPwlDuR2d/Z2YnXr1/H\n69ev4x//+MeDbLu+vt6o4oiYnbiQ7Y6NAAaSXQZUfMiTuxmuQ3hHh9iU6+DX9FGr1WrsscF1IA9r\na2sN0K2VURpAIAQG3trkOa+GjMIEGjFL6OEn3W632BaQ9Oeo3/dqSwCTEH9zc7NUkCwuzvZAybmQ\niChj2sfQdzqdAu6WDOl/12/zfhKfyDgejxHNfaTNvG9r92a6OUzPIYszvZ5ZLYJbYLZ+aUkBYLeE\nkR/U35dnmszc8n1jXHQ5jLuyslJCO68Bt6YLUFv2eGizPp1DFT+vKxFc/WEANUOzdOMsuPvGn+N7\n/H0uuTLLdsmYF614QpxOpyUs82YhTCpolOx7sbOzEzs7O/HixYv45ptv4quvvnqwbbFPDuuzz9hv\nIqJRzuXoC3KAnXzt3Mx8AMk8kdquSAKUWcGkAQzsBAg4sey+gWWSOALkMzl6aMtEy8vWkYcAQOyT\nscN9wLiyTOEjp7wxPH/Ht7m2G2CcpTT8zzkfRzf4Nv2V8yG57yKap1d7Ar+p3fsM8WykGgAadC3Y\nu+Ce9zr8zUkLAxG1ddlh/D4bAgZNZxusrKUxc+EkeSmmS7EICQEcBuA8khEAW43NZ1ZvwMUuWbz3\nDOzoAtC1vGDAzVKRbcbf6S9CO1ha1ny5JwZL1r6YhNHbNjY2SrLt1atXsbe3F1tbWw+2rSca+x7P\ng09a30Oa4WUNHV8lH5B9Kk+UgLbLHl1a5vtgpRVgQ0lertX2Tlf+LnToVqtVIhESlOiMvOYlLdCY\nXCKiJKA2NzfLM/hZI5oniXhitzZrXPDCHcYeLedtjBvIhIzjvBy7RsqcsLbcVCObjE1HJtzzbe2L\nQLcGgB6o1s0AOK/mADCyYxOmcR0GSmYjGUxuusfMEGE4yA550QUO6z0FzHT5rMu4HtpyUjI/B89r\n0M0OlicVXy8zvBxW838Ysr8PsLJjm11ZxnClBWEf4XLOBSwuLhattNvtlkQJe8+SvHhoq0Vflrcy\nA8Q+yGJOFCIZLC0tNUqPaoBLy6Cb2S72iIiSBScHQTUNLNm16oBDRDNScvklFQFmuo/RrKmS9Wc3\nOfbxyOG46/Wd/MVmGfgAYE9aADUgymedp8CHkXUs7ZhE5IRcrT8ztvhvJNZ534NXpHEDOTuLcM3f\nPVD9+zxYfd2sj/JipZIN6k6usbiIWelHu90uJWK+PwB+YWGhaD7MeN7DgcJqL1PlGQy6Tmh9afME\nY+2x9szuAwMHNnPJWM0+WZfPE5adLk+i2JPPA6beOwBbsw0hn2U/XaQImIa1M9hBjfl/abtpEsrk\ngEGcmRL+jD9ih7xqKkdn2NEZ9LyyM5ODPJ4AUMsaWZ6o9V/EdanccDhsZOnn3WoTTMR18vLly5dF\njnNFkRdusHkSizjwYdvQ2ygyAdGvxguH/rbbs2fPij2m02nRl8/Pz8v1fRKHK1kAdY8h1+QaVzzG\nMhGstXvtMsaDugOZPT2AnbRwGYZnQtdKcp3aHpjWX63BZUPkh4SNXF5eNkA3YrZMlcHuVVUkztiU\nZTQalWwq131s0K2BTZYH6GieyaVtlkL8eZpLXnxtRyV2JoOTXzgr54Gxso/+n0xmy38ZTAAVEQVa\nJ6Dr88zmFf7mCTqDKf6bAbP2PoeRjgBq8o3DZCdk8h4mZrv8jnHCJGSpo5bI5vMZdEejUcnSP3bz\nBNLtduPVq1eNiAfmx8ZS4/G4jLHRaFSiSUeZEdcAfnl5GRsbGwV0Tcx4EYlk+RM/Gw6HMZlMykZA\nbFCO/OWEpEG3BqDggL8vg25N43e7N9PN4YF1mBwG+0YzdeeF43qtdGY5NqDBgPvIA4nQy+GIjUd1\nhDUivtMOgcOyK1KeMMzsH9ryAMZmEbMCfuxlG2fdykzXiTLAICIaSSD6tDbL3zXBwSiwsXfJ+vTp\nU4xGo/Js7DQHu4WtwQQJRwmvzSDnadsMvkxg6Ph5oPl9ETN2hX2tEWcGbdmpJv/kVvNzrpGZFa0G\nCLBxdoXz3gt8Dz/nNbHl51hbW4utra1ot9tlRRr3yv+pIPCxRAAov+N52u12qSJinFIVwXWYGHPI\nn8mCmbbfU1uI5X51/9YSa0zW7r/b2r1AN3d6TkbkAcq/c4fw+8lkUlYxeXMKh2SWJcwMeMisO/Ji\ndiMxZmAwS+WZPMMCuIQ8rJKyPIJjz6sZZKwz8T3eVAfdzvftPResh/F8XMO6GWBrTd1ld2YMtSRC\nZnYADcDKe2BchOfODDMxdrvd2N7eLs+Ifj4PUHCyK6JZnQGYejKt6dq8176W35MHOEDOTmrt9vUx\nNkROlrloWSrAB/K91LRjfIPvPDs7+wx0HxtwuU/K/yJmNeQwWUiN90PJJzv4tAn0bbDi9PT0M9Ae\nj8dlz16Amb5iXOCD2IkJ9Orqqize+PjxYyEP5J880TKOnINyxYhrsh8NdHGA2gxc+7d/N5lc72sA\nwGFAL6+k3fQw2eFzssuAS+0jINNqzTbfwbBMAD4qxUuH84omVwI8pOEoEU1dlb9ZoHeyhGWWZrhs\n7kxJTLvdbgCumSqgZ8A16FrfrSUWsvaZfQVWgtMvLCwUjY7vWV5ejm63G58+fWoUrc8LdK0R+noG\n4Vx1we/5aUZrhuxoxxUSREZUwaBtc3LExcVF0bZrTBU78v98/54UM5D6O1l9ZRZ4FxjMo1k+8ngB\nNL0PghPWkC/e02rNTmIwswUzfC2DLv3gCHA4HJaJnxesGpthX68RoC8ZXy5rdfLYe9PcJAG53UuU\n9GCKaK7wyQy2lqThQR2a+fQBjOWltVk/zeBuJsZ3OCFX0y4jZgsE+E6zbe7JG0n72gjy6MDzAF2X\ncDH4zRZzmRi/514dJtsWsHGDMrs/eRUUtbI+BgVmh/PBqO0PAEuuMuH+CdXoY/ZoMIAsLi6W7T+J\nfpy8modtLRHUwnPb189ElUh+v30pMyrsDKicnp42mBEJpe3t7UZ2H4CqZc4N8L6PDKQGGh9T49D3\nsVueBJgADJI+TQabWdrj7wsLC0VyGAwG8fbt28+OIXKCt9frRavVKokybxbkXQGNQeRC6GfYLsuV\nLQkBzi4dxM/b7XaZbIxJN7V7L47Ig9osiN8BvLUQxsDFLJMPzuOY6IuLi0bW0svvMsuugS7iOuCF\n42V9xxqST0OAfdrh6QDYE9d5aHNo7lKZWgVBxCyMBMwioiQHrQU73OQFM4iYHZH04sWL4jT0tR3O\nAxnWRRRhrZLPOmO9uHi9U9ZwOIz19fXGHhYRs/192+12kSJc8TAP2xp084BwKIpubmZjnS4iPgM+\nR1kGkbxKj8/jg69evSoJIuuJ9tlMMPy9/DsnpF2Xah00k6N5tAzieULDR0ejUWPPA598bIkMJgxA\n4jsfPnyIfr8fl5eXcXBwUP6epTZkCg69vLq6+mx7gVZrtpkV9jo/Py8k7OLiIjY2NsrYM+A6UnYN\nMd9DZYX95aZ2b9A1c4z43IENuNb9HIJhGM9UDpvMgBnIMCdvZJMTJHZ+OsUZYO7fIOLO5pXrcv1c\nniGt4T20GXTN7msTCgzWoRNAZ73Z9rAedXJyEsfHx0WKoHrDm8MvLS01jtcxs6A/uUdrpvQ9AE5d\nKqw8bxxE31LsDwO3ljaPlpmufdN/zy9AFzkn+3OWmZyEI2LzM3glY7vdLnsRGBRzdU9mjr5v7p33\nwiqpukF6qunAj6Xp+nuck3D+xkSLlyUGjyufjjIYDEqEiWRCWM9JGsPhsOxcdnV1VVgrq/lWVlYa\nu/Fxb5n1Um3h6Ni6rSOiiCjnF9oOt7U7QbeWWa+F7jgAnWxAdAcAcAz25eXlzzbnYGahnAQQ8ABg\n16DxeNwoM/PuT16GmAHaCTh3gouo+Sxr13Mmc17OywSBEzEg/XItKZ3v+/HeszljzqThSQXQODw8\njIjrjbG5LkfrIEeMRqPSr0tLS+Va1OliL2zGpjfn5+cxHA4bh2J6wrRsxGIJO/VDG9Uatb7KslhO\nhtU0+wx6HogRM9kFpu7Pm6CYSNDftRWOtfxIfg4G+8nJSbx79y5+//33OD4+bmxgXpP85tEyuMC+\nWfyCDyDjOXlWK/3ywiikguFwWHI0RETeJ3lhYaFRAcVSfk+wJBcd7VmCcIKUifHq6qrs1+tcFs0J\nb/vQfXI9d4Kuhfw8GzuZwKCiMzCKNT9vOOMTgDG4hXWof6t1XWxvEbvVasVgMIh+v186FZoPCED9\nLUnUADeHiO58a9H+Pw72GKCL1lorE+K902nziBsnEVw2ZieZTqcNp2eSgYkeHh6W7zw7O4t+v1/q\nGyeTSUkUsIcGfdPtdhulVNPptCTIPnz4EL1erzB36/pmu7AW7xTne//Shg84URJR3yHPdgQ4HdnV\nJDMADcAkUmFCMtO1Blvr71y/7pYB1z+5r+FwGO/fv4/ffvstjo6OCmskCX3TNR7asi3NFEmSXlxc\nxNHRUYPl5siUl8kNob9XgAKYTozlzzM+aPSDE3YQhTzpus8tG/BsPCs+ml9zAV07IQ+S9d2I5m47\n/J6BA2i5cJ/Z3g7rZAJJK38OUJhOpyWM8uos66AOQ2yQXOBujdcvD/qc1Z5nYxCa+fhUZDu05Rju\n5yZdMcs9EbOkHXZGx6SUic9QckS5EwObKhAcnfeenZ2VBRM4vBcFULEAWLN3rqUlyvzmqT0uLS2V\nY3W4pr/TdqyxXYNVTcO0bXjvwsJCOQHX+yTs7u7G3t5ebG9vl31x8zFYvp9sh9pPa8v9fr8wXc6t\n870/lqTge7ZdYLvdbrfs+Mf7MlD5szl/BIjlRVpOELt6ydUoXIPP8G9/lyMBV92YfN2l01qCRLe/\nrd0Jut7KzplWU+78AE7GAJrO/NvR0CQBTcCH0hqMy6yIkZntuB4JCToXWaDdnm2042SDw+4848LG\naoPVbV4Z4Zq84OvbvgwmACJLIpYUrLNyHSIGvotGP6G7u9wKP/DKN8K20WhUTjRg2SW+wjl3bHoD\nwHc6nc+qP6jRjojP/vYQu9YqbGxXfg8L9/0ziUc0FwllX4+YRYTtdruckLCwsFCqQ7YMtS0rAAAX\nKklEQVS3t2N3dzd2d3fj5cuX5XjyvOPVbS0Dr7PwvV4v3r59G2/fvi0Ryrz8867mSYKGr3lvE9i/\nJwHGPXKgiZf/5vIs5xJqYO86WvdXxGyXsXa7XXzcEl6tcghfsMzhSNTvvY/N7wRdMok8DLpNTdzP\nDo5hSJ6RQMgLFPgc17+6mp3ciwAPWDoJx/uWl5djfX29gK4Tbr5PTwDcYwZdSwu3MaR5ObRDVOqK\nAR/uwSzeEQD3DRhaX3Kk4Sx83jbP7JgEkJNeBm+kn4gZSJNwQ2aYTqeNjW8AXUCaWlVXiODwJEuz\nHvqlrVZdcxNzdTTjVUf5WgYFBjUMCaYF019bWyvHFbEfLDtwsWE713G/3db8d4jFxcVFYbpv3779\nTNf832oZACFAZvS2Ke/FZq59xd/xJ8jCx48fSxLXZWH5OnlRVUTzdBTnGFyayj1l0M2LjjwJzx10\nYbqwsTyD1hzZ+p01XX7ngYBG699ZQ3Z9o52e66K7eCMR031rupYVaLBF1wvnAX9XePGQdlM5E7/L\nz12babOsgw3MyBxC8TtCJ09UEddswAyajC+aWMSM2Vkn5noedJ1OJ7a3txubw+d1887ek0SzJvel\nrcZ0sn1sEw8iQDR/1hPb1dXVZ5/1oF9fXy+nYBANeDNsrunKB1r+d35FRJydncXx8XEcHh7G+/fv\nS44DNulnmbe8UNOVI+rlbWAHNdkeY5ZWIHRMQs65EF1h19XV1ZIfMuv1Yp+c8L+6umocgklEy4Rv\nWY9JM59AftOYc+R8V7sX02WwLy8vV7VbXnbinNTxg0PrrcHcFAbioF6zz9Z7fB6G6+oGBkxEc+nf\nbaALcGTdx85kp5uHI5tVO4LIgFtjWvnvTmi6L6xz+b4BDVhBRPOUYSomYL4XFxeNbC7M28wVWxl0\nd3Z2SjWE2XneppCf8wJdT0y07KtZMqDVQBcykZ/TNvS2oZubm7G7uxsvXrxoLH3O0kUNFHPInsF5\nOp3GeDyO/f39ePPmTQN0/Vx81j/n0WxHX9f/d6SFZm/9lcUxNaZfI2zT6fXxSZyD5pIvV8TATBkn\nALcPJbCMSOkiG0K12+3GaeR5xWbNvvjLfdpfAl2HhDY8xsrJH24kl1rREQy42gP5wZyBzddyyOCZ\nvdVqNbRcz7A2DmDCxhtZz33sEC1rW7ZrTSdzCJVPbbCeyzUMCO4vbGEdy7b1pAiQEy0YhJB8sF1m\nOGtra+X7yBpb788SCM+Yw9AvaTXArdnUE16Ngfr/2MnRGKQAWWhlZaUhm9g3TUbyd3I/teb7wHZU\nLPz888/x/v37stzVZWz+7DwbtsjXroG9mS4EJz+/xydskZ/2WSZyNpP3mAZ08R+ubUmRcWBSl1e/\nMhm4siQTwxoGgit32ftO0M21i7mUx86Q2R83icH8Mih4xQgPw+884JmlnJ3nHvkeC+F8zhl+vp/G\nqrThcNg4ZDE7Um7zAuIsG2BLRwcw2Ol02tA+YQ+5CsMs39e3U1uDgg2QlHHCDP231ZoVozuM8lJP\nDyZAEwd2oo3kUZ5wuefbyqf+SqvJCvd5v4HYWh7XgTU52ejJsNfrxerqamxsbMRgMIher1e2duS8\ns0+fPsXa2lrD932fZsL5WQCuw8PDePPmTfz000+xv79fopPaZDPvZhyoTRoGZJjuyspK46h1y5bU\naQOOjGVfw/7iEyQ8XuxP+DT38vHjx7KhlgGfRTwsKfb3mNBl/zE5sWx6l589GHR56Ay4dlyAz4kw\nD3rXpvJZbzLO97rGzw9uEPegsc6CjJBXm5E8AnRzWZafJxt0HsCbQZf7xlHMBJikfBKHWa3DLYe+\nzPq1RShmx/QRUgusCfkGgGBfBPqEdfWwXQDegAXoTqfTxoY8MG23eYLubX+rRVZZL+cZPJFTbE+C\nlyoaAwOMrNfrxdHRUTkNA8CNmI0bR3n4RM0HmRxJSB4dHcWvv/4aP/30U9Eqza7nJYHVGmPoJsDN\nNnXuJQPbZDIp5CFiBmY8s5/fzDQn5iAigLUTzPgqoGu5EjsByvl7cqvJCvj7TX3ndifoXlxclJvw\nihEL51kTy7OCnRGWZgEckdyOzs1bH/biBYeirqww2MOSMYoBiudgtdvJyUnZeNstTyTzbjVJJrOI\nDA6WInxPgKKzqNgHeShHHFSWUF6HTRkczijDLihaB+Qnk0mcnJwUtus+pO9hMhFRVgzmZCD2zuHx\nPGybw0H3qyOJLJn5Ojk34ejJ44Fnh/3Yz9iL4PDwsBxrs7293Tjh1xMu32f/ODs7i16vF8fHx3F8\nfBz9fr/hL7e1eYGwoynsa43Xdqf/OY3XkQ1/B5RdepfHOFGTS0MdadfYaESU9wKyKysrZeJrtVoF\nVyKaib2IqJJMfMFYkknGbe1Ozx6Pxw3QzYwXZ62BL41BTCnNZDIp7Ig1/ab2aIVoyAxulzcxYL1j\nFvdjndezkbVaAIf16jDdrFnX/j1P8M2zZi0D6okks7Gac2aNCzDGQQ0Y1HSSJPNyVOyYt7PLcsR4\nPI719fWy+Tv94jCS0zra7XbjiJTaZG154qG2daidkz/+vwcXuYJMLHyNHPbSd/YfGHG7fb0py+np\nafR6veLnW1tb8e2338Z3330X29vbsbW11Qip+T5+EvGcnp7G0dFRHB8flwVC9geH29z/vBmvk4x+\n2b6WxFgocXJy8tmE2mrNthrFb10+CdC6fh2JJ1cveFELeGFJjo2X8t4PjtIcnd82Fp0DobSMZ7mt\n3Qm6Z2dnheVkTTZLCDXQzazHNW8RsxAfLZUOI0z2fg0GfVdUcD9Zg8PRAF07Xg10XfZkZ6c9BvDW\nQhVnbLONAaMsS+AEyDGAKrqv6yTtkNPp9dlRZhx+Wdvi/7BcFqgMh8PodrsxGo3i/Py8wVr4Tpb5\n+no1wPXk8dDmScrygO2J7XNk5ojjJgbFvUbMqlAMvCzimU6nRcskyru4uIjt7e04PT0tfb26uhrd\nbrehH/v+AAKkhV6vV0A3M6yar9Z8+kuby+Uys/P9Rsw2NqLUK5fMObqyzVlYwou9ddk2E7s6kvX9\nMJY4L40EJ+zWW7p6K8wMpm5+ZsYC0THvrUkSbnd6dl437xAfdLdgzXswnjUx603dbjcWFxej0+k0\ntBc6wpvYOEzlwQEAh2UslHAWEmCxlhsxO0cKdubKhbuccp5M151bSzRmgMjM1nWI/kwunamFRPSR\nQdKyhF84siMdwuaTk5Podrvl3CsSb9bdctka7AxtOg/eedg4SzZZPsjfYS3dwMm1smZLGGw23W7P\nEsMkENfW1kofMMlxYsH29nZJ7LDfCBs10bdm5h8+fIjBYBB//PFH2WOhNincRg7mwXyxERNUnkBz\nlADwdTqd6HQ6cXp62gBL+yL+RuVAxGzryogo18LXHQFzb54A0Wnt97lGl5/gDs/g/vfzcY2s4VIy\neFu7F+gyUHhwJ6QcVplhcXNmt3bQxcXrZaKm9742hq6F0tPptLFsNoOus+PcoycCnHc4HMZwOCxb\nztUcyyETz0SbF/jadjeBbk4u3ZYwwb62Od+TGTXvJfzyqpwcsloTxq6AbqfTKbouBwlmwF1cXGzo\noK1Wq1RD5OeYJ+jmcDv/382DFRnF/RAxIxIRs72MrXsDtABMt9ttMFVW8S0tLcXW1lZhYIBuRDSI\nCvdF5HdychL7+/txdHTU2F0uP/c8yUFuNcCtSQz4GDjy7NmzkiQ32aFB8lzTHDFbAZlrnZeWlqq7\nlHmidcLNFT5Exyy9JzLh+zLoWnZjDBnrIBoPBt2NjY3yb27Ye85m9sDNmJ3CDJz88WD2mn8SO7mZ\nqdE5md169YiNlMOEq6ursn2hqxZq8ogN+piA69na95pn1yw5GBjMGGBWfAfPnSdKBo3BNj+fgdrl\nZPRVPmiQRKdZssGX/o64Lh/L0s9N4fxfbTXA5Po14DXoI+XUksaONvBt8gpol7wIjZ2Mw07tdrsA\nM5r75eVl2afCoSxy2HA4jOPj49jf349er1d2e8vtJvvNg+VmW93UAOaIKJNSp9OJ58+fl6NyxuNx\nA7iJXsELPk/EmkvF8j2Zxeb+jIjGbmQmAxDLiBmrNjHJMpjHm6NQche3tTtB9/Xr1yVstMZKQizP\ncr65zFBtHBqzgx0s1+7BgG3IbDDYmrWtbBQ+e3l5GaPRKI6OjmIwGDRYbgbW2kCbJ4Mwu8+Jwgyc\n2ZHyPTMzO/TxfZuh8rpNVoF9UW4H4FJiR5SAg5qlRzSlENiLNeHJZBIrKysFaLL/PLSdnp6Wgnrs\n4wnE+mGWZ/Ik78/zrEwcjvDyrnf4Iro6ZVPr6+sFYJxYhEXlCh222/zjjz/izz//jMPDwzg5OSmh\n8GOy2lqrfd9NUYrt0el0Ym9vr0ROPAOfJ8z3/iP4KRMVJYnelyVX5pgQwo6d8HSJJn+PmO0fTgle\nrmby89m3vXcKVTo3tTtB9/vvv493796VwnfvU2AHrc0GDoEdJhk4+BtaDszBdaQGi9tAx2ukc4gR\nMQMuQJdyG0D3Jgkhg9c8HbwGuAYKZ6Pz8+RmbTiiuZYdzdAAiy0sZ/i5W63rbDkRCMBr0HWCk1ee\njLmeQRew9wkY86paoJFsQVvGfpbGuDfslaO2mq2xM4nXnA3PchDjxHKYDzK0fOfrcx3K9I6Pjwvo\nHhwcxMnJSYMR/182S3C5OeohUdhqteLk5KSRk4iIMhGxZNj+x4kyTNpEWJ70s06MpkvuBz+zRAHo\nOoFqOeemZ/KzQfpWV1cfDrp7e3ulRIUHImudwzezsiwwc4PWfPLvc/WB5Yr8b4eHXMuaLwZzZQPL\nfdkHwCemGlTzfT2mQ8NAz8/PS6c5PK9pjDiVn90/zebcMgtgcKN3M/lFzDRElklzBAyMy9KM/WI0\nGpUyHq5jBuQIhXv1JDNP8CVZ1el0otVqNQZuzri7WY7BPky8DFCXKPJcNf+7qdqEWlMmIsJY3xvX\nYevG33//Pf7zn//EwcFBYXi1EDv7a42tP1RisFR404v7N3j5rDTfv/Mt9gFsm/vDy89zriFLQnkM\n8fsamcr9dNtzmjB6e9kHywtbW1txeHhYwkBT71ooiQFztpgb93vNMGgGcICXn2Zkdq4Mjgxk9Buu\nQRLi8PAw+v1+nJ6eljIRazq1az4WAKPXjcfjWFpaimfPnpWqDWSXnKi8j9ZoUHXEkKsPrOv6XDPs\nhpxEYf9oNIperxf9fr+EhnzPeDyOfr9f2EfWTS0z+Pw611DbyR/azs/PywKEhYWFGAwGnzHDm8Jk\na+3e3pSqhMlk0igNcrmdM+X4l0EI1utaZr4XnwBoYM+Hh4fxyy+/xL/+9a9yQON9wDNrmvx7XqCb\nJaSIzyd+7y7HEeqMv4wTxg7sQK0tk5KJgr/HDNcM1BFFjr49UdbGU84FGJscibDEm5ri29q9QLfb\n7cbq6mqMx+NC971LTx7sJNJqOqQTaBH1reHshL5ORDSMmj9j0Ad0vUnPxcVFDAaDouUCuhivpus9\nNtMlgeLjpT98+FDYjzOlsGK0qewk2VE88IlMDMJmwgx+sriEbIDuaDSKwWDQeI3H4+L0LE016Dri\nMYOBGfA7A7MHwUMbG+Fvb2+X+mXO1Lstz+AJCz8iNKU6AeA0QBiYzc64F75vbW2tUU1jAOMndsOH\nDw4O4s2bN/HLL79Er9crk91tvlkDXFpOIv7VVmN9Jj0GRx90ysRNpYuTxgZe9F3nbZyr4Zl4Ty7t\nIi/kU5a9CjJfM4/9rMnXnpnvZiLOizhuaneC7traWqyvr8fm5mYjY80mMabVEdEY0Bin1WoVLc+d\nncHNM2WWEDK7dXNHwQAJObyV4GAwiD///DP29/dLYjB3eJ4M8vdwf/Nqf//734s+2m63y5HTXqTB\n89HRWdZh0HtiA2RgSj5Zwi87IX2JZADYHh8fR6/X+0ySsT18esEPP/wQg8EgdnZ2SlWJo5z/+q//\nik6nUwbWTdUtD21ra2vR7XZjc3OzUYd8eHhYqgFq4bZtjoaN1thqtUq9qfvHK/8oGfM+A660oaKB\no9dzwpRnPz09jcPDw8Jy9/f3G4nfmoT3v9lsJybzfLo2kp5PAwZD+B2TPbor4xcyxMKadrtdIkHj\nS96qERu6Vh0/z5Okk/g5KqsRwCw/cH+dTqex+OO2difocoTx1tZWKa1iNcdwOCxMjTXj3nTFgGtn\nqs2yOJBB2DNajf7b6XOIYnGdTu73+w3QzRPATQ6cwXaejv63v/2tHLNC3SKaroEIG1kS4J7MMnAm\n7jFndPMrOyZ9iIzEsdZHR0eFpeSFJhHXCcFerxcREQcHB4UJR8wK3rlXF6s7ROM984ouIAxbW1tF\nZ4MVjUajiKjX7OILRAlMFCSBAF0kEp7RJWOdTqdUJeR6ZWQID177PG08Hse7d+/i559/jn//+9/x\nxx9/xMnJSQM47kquPmYz6AGy/X6/aP4uJcwbjpuYsVpsc3Oz2P7jx48luYW/EFlYioKEOEnsv3v8\ncF2kr2yz/DtHwE4OmwUzYVAi6AUdN7U7QZflezs7O8VwaGOcN89SU/QXQIMHcYImM1rP1gYOP3zW\nH6391DQhd4Kz7f1+P3q9XgwGg8aZbdwnP/OAf0x54fXr18UeR0dHJQTzTvZeVQbwmvl7Js9ar8Pk\nrA1fXc32080DmOwwoeBgMCjspOaw7C0wnU7j6OgoDg8P48WLF0UrthYG4HCPPMO8JR2K8FleO5lc\nL0u+uLgoS5ZZv38T8OLLsLLxeNwAAexOEhSgX19fLwdyGnQzg885g4hZLSnJs59//jnevXtX/DaP\nm5vavGSaWjs9PS1jnYiIvSUAXkDXpwDnZ221Zqc07OzsNPa+5T3Yjmg6A18NdPP3OHKx7JhLKDO5\nc14pa7kwZfxrbqC7uHh9PMbLly8L0A4Gg7K6yOEEIW1Ec+f3TOUtZtdCeL9cE5lnyZrB+DedwCRx\ncHAQvV6vZNetp9kxb0qwPBbwbm9vR7vdjvX19Xj37l3R7NjzYjqdNuoWaxIDwGk7OFylr2xTlzdl\nHZUwkfpslkozaGwP67JEQL1eL969e1c2cNnY2GiEXGYgOTkxT3t3Op0ibSwsLJTwz8QAgPC6e+4R\n+6FXm1Sgd1Of6ZAV0HTEwTM7+VbTXJm8+v1+vH37Nn777bd48+ZN9Pv9klCyje4zSblvb4vo/koj\nWmTfEqQnSwteaZrlLO4Jf+10OvHy5csSlZIoxMYmIfSNMSAn0rB5tlFNx8+kLYMu/p1Bl+gGNcD+\ndlu7E3SXlpbKippPnz6VEJ3Ba+3GbIGZBEfBMb101RvT1Ki+jZmXHdfC5aztkvQbDAaxv78fx8fH\nBXRroQetxj4eq21vb8f6+np8/fXXsba2VpIkaF2TyaToh9yzy74iomHfrEthB+9elcuZbO+IaJR/\nGXRrzeDLxNjr9eL9+/exs7MTm5ub1aRfHhC+3rzsjgSAxEWZlkNQWGwuv/KkNZ1Oy6TDngHYESbt\nyc+111zLNaG2ec4jTKfTOD09jYODg3Kk+q+//lrGE1LdfcGzBjLzaOz9wG5nRJG5UsP10BGzJdT4\nMQmwTqcTr169KuyY1+npafkMe1hgAwDaRMJSAAz1LpLHTxM3E5os5dGPJNAA3W63WyaG29qdoGtn\nIlTKIe5NupI7wA/0V8Mefz47aS00yO91OP1/pX/d1LwdHHtG+L5rEkqWQgxS1sb9/yylOEN+24Tn\ngXMbGNbkHS8Vd8uT2mNo5Ty7v8MhoXXVu0C+JlvlmtD8qvmrnz1f382Zf5c9/r/UnKB2YiyiGSXk\n8WafMyvNGONFE/ZzS2288pio/byt+T03vb/mIzWNdx5k4b8jYvr0uvX1319o24gn+z7Z9v9P+z7Z\n9vFs+9Se2lN7ak/tqT21p/bUntpTe2pP7ak9taf21J7aU3tqT+2pPbWn9tSe2lN7ak/tqT21p/bI\n7X8AH7hkruYJQZwAAAAASUVORK5CYII=\n"
     },
     "output_type": "display_data",
     "metadata": {}
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import struct\n",
    "from numpy import *\n",
    "from matplotlib.pyplot import *\n",
    "\n",
    "# Get the figure and axes.\n",
    "fig, axes = subplots(2, 4)\n",
    "axes = axes.reshape(8)\n",
    "fig.suptitle(\"Random Sampling of Face Emotion\")\n",
    "\n",
    "# Plot random images.\n",
    "indices = random.randint(len(X_train), size=8)\n",
    "for axis, index in zip(axes, indices):\n",
    "    image = X_train[index, :, :]\n",
    "    axis.get_xaxis().set_visible(False)\n",
    "    axis.get_yaxis().set_visible(False)\n",
    "    axis.imshow(image,cmap = cm.Greys_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = X_data.astype('float32')\n",
    "#X_data /= 255.0\n",
    "\n",
    "##################\n",
    "trainNdx = int(total * .8)\n",
    "X_train, X_test = np.split(X_data, [trainNdx])\n",
    "y_train, y_test = np.split(Y_data, [trainNdx])\n",
    "#########################\n",
    "\n",
    "##############\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, basewidth , basewidth )\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, basewidth , basewidth )\n",
    "###########################\n",
    "\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "#X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "#X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# one hot encode outputs\n",
    "nb_classes = np.max(y_train)+2\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "\n",
    "################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Construct a neural network: baseline model model_1\n",
    "\n",
    "The major components of our initial CNN model can be summarized as follows:\n",
    "\n",
    "1- The first hidden layer is a convolutional layer called a Convolution2D. \n",
    "   The layer has 15 feature maps, which with the size of 5x5 and a rectifier activation function.\n",
    "    \n",
    "\n",
    "2- Next we define a pooling layer that takes the maximum value called MaxPooling2D. \n",
    "   It is configured with a pool size of 2 x2.\n",
    "    \n",
    "\n",
    "3- The next layer is a regularization layer using dropout called Dropout. \n",
    "   It is configured to randomly exclude 20% of neurons in the layer in order to reduce overfitting.\n",
    "    \n",
    "\n",
    "4- Next is a layer that converts the 2D matrix data to a vector called Flatten. \n",
    "   It allows the output to be processed by standard fully connected layers.\n",
    "    \n",
    "\n",
    "5- Next a fully connected layer with 10 neurons and rectifier activation function is used.\n",
    "\n",
    "\n",
    "5- Finally, the output layer has 10 neurons for the 10 classes and a softmax activation function to output probability-like predictions for each class.\n",
    "\n",
    "In addition we set the \"adam\" optimizer with learning rate of 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer='rmsprop', init='glorot_uniform'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(15, 5, 5, input_shape=(1, basewidth , basewidth ), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): We did not found a dynamic library into the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.795625 using {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 16}\n",
      "0.685564 (0.134541) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 8}\n",
      "0.771249 (0.005575) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 8}\n",
      "0.763134 (0.014076) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 8}\n",
      "0.784390 (0.017052) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 8}\n",
      "0.781892 (0.019782) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 8}\n",
      "0.773151 (0.029946) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 8}\n",
      "0.751905 (0.035689) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 8}\n",
      "0.786253 (0.009237) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 8}\n",
      "0.736262 (0.038433) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 8}\n",
      "0.792498 (0.011735) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 8}\n",
      "0.788122 (0.003224) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 8}\n",
      "0.775640 (0.020497) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 8}\n",
      "0.691349 (0.111471) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 8}\n",
      "0.770649 (0.027566) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 8}\n",
      "0.781876 (0.016865) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 8}\n",
      "0.761895 (0.022641) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 8}\n",
      "0.711972 (0.111021) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 8}\n",
      "0.782514 (0.015782) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 8}\n",
      "0.776261 (0.013703) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 16}\n",
      "0.763753 (0.005371) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 16}\n",
      "0.791256 (0.008265) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 16}\n",
      "0.780011 (0.012637) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 16}\n",
      "0.751913 (0.043173) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 16}\n",
      "0.719454 (0.089179) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 16}\n",
      "0.711876 (0.038327) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 16}\n",
      "0.752507 (0.008316) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 16}\n",
      "0.776249 (0.003883) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 16}\n",
      "0.773747 (0.011354) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 16}\n",
      "0.788755 (0.015577) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 16}\n",
      "0.795635 (0.023783) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 16}\n",
      "0.660578 (0.069386) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 16}\n",
      "0.681222 (0.119287) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 16}\n",
      "0.731234 (0.057982) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 16}\n",
      "0.781264 (0.016596) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 16}\n",
      "0.792505 (0.007723) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 16}\n",
      "0.769396 (0.023696) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 16}\n",
      "0.749397 (0.025579) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 32}\n",
      "0.708821 (0.080840) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 32}\n",
      "0.677440 (0.136747) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 32}\n",
      "0.782515 (0.021440) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 32}\n",
      "0.791882 (0.018554) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 32}\n",
      "0.778121 (0.010284) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 32}\n",
      "0.648058 (0.084563) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 32}\n",
      "0.755629 (0.015275) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 32}\n",
      "0.778746 (0.004240) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 32}\n",
      "0.777498 (0.014750) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 32}\n",
      "0.773764 (0.018966) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 32}\n",
      "0.775017 (0.022785) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 32}\n",
      "0.648724 (0.115017) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 32}\n",
      "0.683148 (0.036955) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 32}\n",
      "0.771244 (0.024706) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 32}\n",
      "0.778758 (0.013475) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 32}\n",
      "0.671195 (0.131078) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 32}\n",
      "0.783137 (0.020999) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "#dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X, Y = X_train, y_train \n",
    "#X = dataset[:,0:8]\n",
    "#Y = dataset[:,8]\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "# grid search epochs, batch size and optimizer\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "init = ['glorot_uniform', 'normal', 'uniform']\n",
    "epochs = numpy.array([10, 20, 32])\n",
    "batches = numpy.array([8, 16, 32])\n",
    "param_grid = dict(optimizer=optimizers, nb_epoch=epochs, batch_size=batches, init = init)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "for params, mean_score, scores in grid_result.grid_scores_:\n",
    "    print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Second Model: model_2\n",
    "\n",
    "The major components of our second CNN modle can be summarized as follows:\n",
    "1- Convolutional layer with 15 feature maps of size 5x5.\n",
    "\n",
    "2- Pooling layer taking the max over 2x2 patches.\n",
    "\n",
    "3- Convolutional layer with 10 feature maps of size 3x3.\n",
    "\n",
    "4- Pooling layer taking the max over 2x2 patches.\n",
    "\n",
    "5- Dropout layer with a probability of 20%.\n",
    "\n",
    "6- Flatten layer.\n",
    "\n",
    "7- Fully connected layer with 10 neurons and rectifier activation.\n",
    "\n",
    "8- Fully connected layer with 10 neurons and rectifier activation.\n",
    "\n",
    "9- Fully connected layer with 100 neurons and rectifier activation.\n",
    "\n",
    "10- Output layer.\n",
    "\n",
    "In addition we are the \"adam\" optimizer with learning rate of 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "###\n",
    "\n",
    "def model_2(optimizer='rmsprop', init='glorot_uniform'):  \n",
    "      #print 'Compiling Model ... '\n",
    "      model = Sequential()\n",
    "      model.add(Convolution2D(15, 5, 5, input_shape=(1, basewidth, basewidth), activation='relu'))\n",
    "      model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "      model.add(Convolution2D(10, 3, 3, activation='relu'))\n",
    "      model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "      #model.add(Convolution2D(20, 3, 3, activation='relu'))\n",
    "      #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "      model.add(Dropout(0.2))\n",
    "      model.add(Flatten())\n",
    "      model.add(Dense(10, activation='relu'))\n",
    "      model.add(Dense(10, activation='relu'))\n",
    "      model.add(Dense(100, activation='relu'))\n",
    "      model.add(Dense(nb_classes, activation='softmax'))\n",
    "      # Compile model\n",
    "      model.compile(loss='sparse_categorical_crossentropy', optimizer='adagrad', metrics=['accuracy'])\n",
    "      return model\n",
    "\n",
    "########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.785625 using {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 8}\n",
      "0.557427 (0.083446) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 8}\n",
      "0.606938 (0.092797) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 8}\n",
      "0.773126 (0.019182) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 8}\n",
      "0.684960 (0.076219) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 8}\n",
      "0.766880 (0.019330) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 8}\n",
      "0.696203 (0.119734) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 8}\n",
      "0.542529 (0.055793) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 8}\n",
      "0.570753 (0.157757) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 8}\n",
      "0.703834 (0.095138) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 8}\n",
      "0.746896 (0.023824) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 8}\n",
      "0.785000 (0.005368) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 8}\n",
      "0.785655 (0.034035) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 8}\n",
      "0.589311 (0.075495) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 8}\n",
      "0.529335 (0.046713) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 8}\n",
      "0.703785 (0.039607) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 8}\n",
      "0.761889 (0.018184) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 8}\n",
      "0.658094 (0.126768) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 8}\n",
      "0.772524 (0.031202) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 8}\n",
      "0.541823 (0.060563) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 16}\n",
      "0.531211 (0.046020) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 16}\n",
      "0.721934 (0.068619) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 16}\n",
      "0.758122 (0.012585) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 16}\n",
      "0.765018 (0.021239) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 16}\n",
      "0.763157 (0.036521) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 16}\n",
      "0.537465 (0.044778) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 16}\n",
      "0.697561 (0.076599) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 16}\n",
      "0.743141 (0.027061) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 16}\n",
      "0.614379 (0.108840) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 16}\n",
      "0.773142 (0.022051) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 16}\n",
      "0.761877 (0.029208) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 16}\n",
      "0.454428 (0.061411) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 16}\n",
      "0.598077 (0.082117) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 16}\n",
      "0.688735 (0.079315) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 16}\n",
      "0.661805 (0.127053) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 16}\n",
      "0.748142 (0.019753) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 16}\n",
      "0.769371 (0.009405) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 16}\n",
      "0.578100 (0.066757) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 32}\n",
      "0.531833 (0.049037) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 32}\n",
      "0.580056 (0.131141) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 32}\n",
      "0.730611 (0.035108) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 32}\n",
      "0.739378 (0.009220) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 32}\n",
      "0.765624 (0.017683) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 32}\n",
      "0.583672 (0.093009) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 32}\n",
      "0.529335 (0.046713) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 32}\n",
      "0.586162 (0.099405) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 32}\n",
      "0.666876 (0.003399) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 32}\n",
      "0.756902 (0.035022) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 32}\n",
      "0.764407 (0.036139) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 32}\n",
      "0.531207 (0.049294) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 32}\n",
      "0.449436 (0.069571) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 32}\n",
      "0.726246 (0.006821) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 32}\n",
      "0.572406 (0.106917) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 32}\n",
      "0.714980 (0.068974) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 32}\n",
      "0.730605 (0.041709) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "#dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X, Y = X_train, y_train \n",
    "#X = dataset[:,0:8]\n",
    "#Y = dataset[:,8]\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=model_2, verbose=0)\n",
    "# grid search epochs, batch size and optimizer\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "init = ['glorot_uniform', 'normal', 'uniform']\n",
    "epochs = numpy.array([10, 20, 32])\n",
    "batches = numpy.array([8, 16, 32])\n",
    "param_grid = dict(optimizer=optimizers, nb_epoch=epochs, batch_size=batches, init = init)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "for params, mean_score, scores in grid_result.grid_scores_:\n",
    "    print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Third Model: model_3\n",
    "\n",
    "The major components of our second CNN modle can be summarized as follows:\n",
    "1- Convolutional layer with 30feature maps of size 5x5.\n",
    "\n",
    "2- Pooling layer taking the max over 2x2 patches.\n",
    "\n",
    "3- Convolutional layer with 50 feature maps of size 5x5.\n",
    "\n",
    "4- Pooling layer taking the max over 2x2 patches.\n",
    "\n",
    "5- Convolutional layer with 50 feature maps of size 5x5.\n",
    "\n",
    "6- Pooling layer taking the max over 2x2 patches.\n",
    "\n",
    "5- Dropout layer with a probability of 20%.\n",
    "\n",
    "7- Flatten layer.\n",
    "\n",
    "8- Fully connected layer with 10 neurons and rectifier activation.\n",
    "\n",
    "9- Fully connected layer with 10 neurons and rectifier activation.\n",
    "\n",
    "10- Output layer.\n",
    "\n",
    "In addition we set the \"adam\" optimizer with learning rate of 0.00001. Please note that difference between\n",
    "the second model and third model is that we added an additional convolutional hidden layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_3(optimizer='rmsprop', init='glorot_uniform'):\n",
    "    # initialize the model\n",
    "    model = Sequential()\n",
    "    # first set of CONV => RELU => POOL\n",
    "    model.add(Convolution2D(30, 5, 5, border_mode=\"same\",\n",
    "               input_shape=(1, basewidth, basewidth)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    # second set of CONV => RELU => POOL\n",
    "    model.add(Convolution2D(50, 5, 5, border_mode=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    # Third set of CONV => RELU => POOL\n",
    "    model.add(Convolution2D(50, 5, 5, border_mode=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    # set of FC => RELU layers\n",
    "    model.add(Dropout(0.2))\n",
    "    #model.add(Flatten())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    # softmax classifier\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    # if a weights path is supplied (inicating that the model was\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # return the constructed network architecture\n",
    "    return model\n",
    "\n",
    "########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.741875 using {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 16}\n",
      "0.616264 (0.118277) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 8}\n",
      "0.609385 (0.088025) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 8}\n",
      "0.453188 (0.073295) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 8}\n",
      "0.741249 (0.007066) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 8}\n",
      "0.625020 (0.143427) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 8}\n",
      "0.536365 (0.162167) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 8}\n",
      "0.565495 (0.148162) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 8}\n",
      "0.633132 (0.105244) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 8}\n",
      "0.553679 (0.080610) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 8}\n",
      "0.529335 (0.046713) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 8}\n",
      "0.637527 (0.074902) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 8}\n",
      "0.545121 (0.167183) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 8}\n",
      "0.552431 (0.078861) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 8}\n",
      "0.505570 (0.064927) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 8}\n",
      "0.416510 (0.316134) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 8}\n",
      "0.581769 (0.120099) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 8}\n",
      "0.681821 (0.138862) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 8}\n",
      "0.376265 (0.314503) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 8}\n",
      "0.529335 (0.046713) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 16}\n",
      "0.449435 (0.068376) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 16}\n",
      "0.665560 (0.128807) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 16}\n",
      "0.682468 (0.094638) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 16}\n",
      "0.621891 (0.124720) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 16}\n",
      "0.741895 (0.031257) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 16}\n",
      "0.499941 (0.067239) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 16}\n",
      "0.529335 (0.046713) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 16}\n",
      "0.529335 (0.046713) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 16}\n",
      "0.529335 (0.046713) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 16}\n",
      "0.531211 (0.046020) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 16}\n",
      "0.376707 (0.274461) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 16}\n",
      "0.341445 (0.220512) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 16}\n",
      "0.550558 (0.076238) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 16}\n",
      "0.489252 (0.348211) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 16}\n",
      "0.529335 (0.046713) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 16}\n",
      "0.586139 (0.126255) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 16}\n",
      "0.576776 (0.113067) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 16}\n",
      "0.551807 (0.077986) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 32}\n",
      "0.571782 (0.106038) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 32}\n",
      "0.598722 (0.062519) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 32}\n",
      "0.481331 (0.104456) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 32}\n",
      "0.583744 (0.091415) with: {'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 32}\n",
      "0.680583 (0.121342) with: {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 32}\n",
      "0.331457 (0.234621) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 32}\n",
      "0.331457 (0.234621) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 32}\n",
      "0.509473 (0.148836) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 32}\n",
      "0.529335 (0.046713) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 32}\n",
      "0.448810 (0.069248) with: {'init': 'normal', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 32}\n",
      "0.620569 (0.098030) with: {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 32}\n",
      "0.331457 (0.234621) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 10, 'batch_size': 32}\n",
      "0.529335 (0.046713) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 10, 'batch_size': 32}\n",
      "0.529335 (0.046713) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 20, 'batch_size': 32}\n",
      "0.448810 (0.069248) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 20, 'batch_size': 32}\n",
      "0.532456 (0.051019) with: {'init': 'uniform', 'optimizer': 'rmsprop', 'nb_epoch': 32, 'batch_size': 32}\n",
      "0.598753 (0.095811) with: {'init': 'uniform', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "#dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X, Y = X_train, y_train \n",
    "#X = dataset[:,0:8]\n",
    "#Y = dataset[:,8]\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=model_3, verbose=0)\n",
    "# grid search epochs, batch size and optimizer\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "init = ['glorot_uniform', 'normal', 'uniform']\n",
    "epochs = numpy.array([10, 20, 32])\n",
    "batches = numpy.array([8, 16, 32])\n",
    "param_grid = dict(optimizer=optimizers, nb_epoch=epochs, batch_size=batches, init = init)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "for params, mean_score, scores in grid_result.grid_scores_:\n",
    "    print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results:\n",
    "\n",
    "Using grid search for epochs, batch size, and optimizer as per below: \n",
    "optimizers = ['rmsprop', 'adam']\n",
    "init = ['glorot_uniform', 'normal', 'uniform']\n",
    "epochs = numpy.array([10, 20, 32])\n",
    "batches = numpy.array([8, 16, 32])\n",
    "\n",
    "The best hyper parameters for the three models are as follow: \n",
    "\n",
    "Model 1: \n",
    "Best: 0.795625 using {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 16}\n",
    "\n",
    "Model 2: \n",
    "Best: 0.785625 using {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 8}\n",
    "\n",
    "\n",
    "Model 3: \n",
    "Best: 0.741875 using {'init': 'glorot_uniform', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 16}\n",
    "\n",
    "As per above results, I will select model 1 and apply my augmentation steps.   \n",
    "\n",
    "        featurewise_center=True,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=True,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=True)  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=True,  # divide each input by its std\n",
    "        zca_whitening=True)  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "##### Augmentation starts here \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "2s - loss: 1.4690 - acc: 0.2900\n",
      "Epoch 2/32\n",
      "2s - loss: 1.1510 - acc: 0.5294\n",
      "Epoch 3/32\n",
      "2s - loss: 1.0606 - acc: 0.5294\n",
      "Epoch 4/32\n",
      "2s - loss: 1.0173 - acc: 0.5294\n",
      "Epoch 5/32\n",
      "2s - loss: 0.9911 - acc: 0.5294\n",
      "Epoch 6/32\n",
      "2s - loss: 0.9737 - acc: 0.5294\n",
      "Epoch 7/32\n",
      "2s - loss: 0.9614 - acc: 0.5294\n",
      "Epoch 8/32\n",
      "2s - loss: 0.9518 - acc: 0.5294\n",
      "Epoch 9/32\n",
      "2s - loss: 0.9435 - acc: 0.5294\n",
      "Epoch 10/32\n",
      "2s - loss: 0.9394 - acc: 0.5294\n",
      "Epoch 11/32\n",
      "2s - loss: 0.9344 - acc: 0.5294\n",
      "Epoch 12/32\n",
      "3s - loss: 0.9311 - acc: 0.5294\n",
      "Epoch 13/32\n",
      "2s - loss: 0.9272 - acc: 0.5294\n",
      "Epoch 14/32\n",
      "2s - loss: 0.9258 - acc: 0.5294\n",
      "Epoch 15/32\n",
      "2s - loss: 0.9256 - acc: 0.5294\n",
      "Epoch 16/32\n",
      "3s - loss: 0.9223 - acc: 0.5294\n",
      "Epoch 17/32\n",
      "4s - loss: 0.9220 - acc: 0.5294\n",
      "Epoch 18/32\n",
      "2s - loss: 0.9223 - acc: 0.5294\n",
      "Epoch 19/32\n",
      "2s - loss: 0.9218 - acc: 0.5294\n",
      "Epoch 20/32\n",
      "3s - loss: 0.9203 - acc: 0.5294\n",
      "Epoch 21/32\n",
      "5s - loss: 0.9205 - acc: 0.5294\n",
      "Epoch 22/32\n",
      "3s - loss: 0.9194 - acc: 0.5294\n",
      "Epoch 23/32\n",
      "3s - loss: 0.9189 - acc: 0.5294\n",
      "Epoch 24/32\n",
      "3s - loss: 0.9186 - acc: 0.5294\n",
      "Epoch 25/32\n",
      "3s - loss: 0.9185 - acc: 0.5294\n",
      "Epoch 26/32\n",
      "3s - loss: 0.9175 - acc: 0.5294\n",
      "Epoch 27/32\n",
      "3s - loss: 0.9175 - acc: 0.5294\n",
      "Epoch 28/32\n",
      "2s - loss: 0.9180 - acc: 0.5294\n",
      "Epoch 29/32\n",
      "3s - loss: 0.9176 - acc: 0.5294\n",
      "Epoch 30/32\n",
      "2s - loss: 0.9184 - acc: 0.5294\n",
      "Epoch 31/32\n",
      "2s - loss: 0.9163 - acc: 0.5294\n",
      "Epoch 32/32\n",
      "4s - loss: 0.9170 - acc: 0.5294\n",
      "Model 1, CNN Error: 50.75%\n"
     ]
    }
   ],
   "source": [
    "def create_model(optimizer='adam', init='normal'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(15, 5, 5, input_shape=(1, basewidth , basewidth ), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "model = create_model()\n",
    "#datagen = ImageDataGenerator(featurewise_center= True, \n",
    "#                                  featurewise_std_normalization= True)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=True,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=True,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=True,  # divide each input by its std\n",
    "        zca_whitening=True,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "####  trains the neural network using the transformed images;\n",
    "#np.expand_dims(Y_train, -1)\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "#{'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 16}\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=16),\n",
    "                    samples_per_epoch=len(X_train), nb_epoch=32, verbose = 2)\n",
    "\n",
    "# Final evaluationof the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Model 1, CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After applying augmentation the accuracy had gone down to 52.94% and the error has gone up 50.75%.\n",
    "##### We need to adjust our augmentataion by normalizing our data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1s - loss: 1.1917 - acc: 0.6181\n",
      "Epoch 2/32\n",
      "1s - loss: 0.8237 - acc: 0.7181\n",
      "Epoch 3/32\n",
      "1s - loss: 0.6776 - acc: 0.7750\n",
      "Epoch 4/32\n",
      "1s - loss: 0.6399 - acc: 0.7794\n",
      "Epoch 5/32\n",
      "1s - loss: 0.5713 - acc: 0.7906\n",
      "Epoch 6/32\n",
      "1s - loss: 0.5328 - acc: 0.8131\n",
      "Epoch 7/32\n",
      "1s - loss: 0.5061 - acc: 0.8069\n",
      "Epoch 8/32\n",
      "1s - loss: 0.4582 - acc: 0.8156\n",
      "Epoch 9/32\n",
      "1s - loss: 0.4377 - acc: 0.8325\n",
      "Epoch 10/32\n",
      "1s - loss: 0.4251 - acc: 0.8300\n",
      "Epoch 11/32\n",
      "1s - loss: 0.3884 - acc: 0.8456\n",
      "Epoch 12/32\n",
      "1s - loss: 0.3732 - acc: 0.8550\n",
      "Epoch 13/32\n",
      "1s - loss: 0.3578 - acc: 0.8563\n",
      "Epoch 14/32\n",
      "1s - loss: 0.3396 - acc: 0.8619\n",
      "Epoch 15/32\n",
      "1s - loss: 0.3219 - acc: 0.8762\n",
      "Epoch 16/32\n",
      "1s - loss: 0.2977 - acc: 0.8850\n",
      "Epoch 17/32\n",
      "1s - loss: 0.2952 - acc: 0.8787\n",
      "Epoch 18/32\n",
      "1s - loss: 0.2727 - acc: 0.8900\n",
      "Epoch 19/32\n",
      "1s - loss: 0.2589 - acc: 0.8950\n",
      "Epoch 20/32\n",
      "1s - loss: 0.2326 - acc: 0.9100\n",
      "Epoch 21/32\n",
      "1s - loss: 0.2366 - acc: 0.9131\n",
      "Epoch 22/32\n",
      "1s - loss: 0.2217 - acc: 0.9163\n",
      "Epoch 23/32\n",
      "1s - loss: 0.2053 - acc: 0.9281\n",
      "Epoch 24/32\n",
      "1s - loss: 0.2192 - acc: 0.9137\n",
      "Epoch 25/32\n",
      "1s - loss: 0.1919 - acc: 0.9256\n",
      "Epoch 26/32\n",
      "1s - loss: 0.2019 - acc: 0.9194\n",
      "Epoch 27/32\n",
      "1s - loss: 0.1909 - acc: 0.9331\n",
      "Epoch 28/32\n",
      "1s - loss: 0.1798 - acc: 0.9313\n",
      "Epoch 29/32\n",
      "1s - loss: 0.1518 - acc: 0.9513\n",
      "Epoch 30/32\n",
      "1s - loss: 0.1769 - acc: 0.9338\n",
      "Epoch 31/32\n",
      "1s - loss: 0.1457 - acc: 0.9500\n",
      "Epoch 32/32\n",
      "1s - loss: 0.1555 - acc: 0.9394\n",
      "Model 1, CNN Error: 41.00%\n"
     ]
    }
   ],
   "source": [
    "def create_model(optimizer='adam', init='normal'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(15, 5, 5, input_shape=(1, basewidth , basewidth ),  activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "model = create_model()\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,  # set input mean to 0 over the dataset\n",
    "        #samplewise_center=True,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=True)  # divide inputs by std of the dataset\n",
    "        #samplewise_std_normalization=True,  # divide each input by its std\n",
    "        #zca_whitening=True,  # apply ZCA whitening\n",
    "        #rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        #width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        #height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        #horizontal_flip=True,  # randomly flip images\n",
    "        #vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "####  trains the neural network using the transformed images;\n",
    "#np.expand_dims(Y_train, -1)\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "#{'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 16}\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=16),\n",
    "                    samples_per_epoch=len(X_train), nb_epoch=32, verbose = 2)\n",
    "\n",
    "# Final evaluationof the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Model 1, CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion: \n",
    "\n",
    "Using grid search for epochs, batch size, and optimizer as per below: \n",
    "optimizers = ['rmsprop', 'adam']\n",
    "init = ['glorot_uniform', 'normal', 'uniform']\n",
    "epochs = numpy.array([10, 20, 32])\n",
    "batches = numpy.array([8, 16, 32]) \n",
    "\n",
    "I selected model 1 as it has the highest accuracy of 0.795625 using {'init': 'normal', 'optimizer': 'adam', 'nb_epoch': 32, 'batch_size': 16}.  \n",
    "\n",
    "After applying augmentation the accuracy had gone down to 52.94% and the error has gone up 50.75%. \n",
    "Then when I just use he augmentation to only normalize the data, the accuracy had gone to 95.13%  and the error had gone  down to 41%. \n",
    "\n",
    "Although the accuracy had gone up from 79.56% to 95.13% , I think that given enough system resources, I would probably have increased the accuracy even higher using grid search with more hyper parameters and more combinations to improve the model… Also, more data preparation would certainly improve the performance.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}